{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc49d9b-5f41-4169-bbda-5d77f285459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c4517-86bd-4ed3-836a-f7356c895317",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3404f6ab-2dd4-4c7e-989a-ea33ee8c14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342afe6a-fe93-4832-b573-96f8e209cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('imdb_reviews', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155f67f-344e-4841-adab-3a2e58608756",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds, raw_test_ds = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dae875-74f1-46d0-a402-03cf4bdd4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\" 0\n"
     ]
    }
   ],
   "source": [
    "for text, label in raw_train_ds.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b56f4b-0c53-466f-a810-48091062b5af",
   "metadata": {},
   "source": [
    "## Preparar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b8f2a7-f119-48ae-8dba-f8fa7fb03b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BUFFER_SIZE = tf.data.experimental.cardinality(raw_train_ds)\n",
    "BUFFER_SIZE.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b380bb5a-b845-4440-a468-147af7bbcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "voc_size = 5000\n",
    "\n",
    "train_ds = raw_train_ds.shuffle(BUFFER_SIZE).batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)\n",
    "\n",
    "test_ds = raw_test_ds.batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48972e5d-a421-415c-bbae-c3b1440ea599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This film illustrates the worst part of surviving war, the memories. For many soldiers, men and women alike, returning home can be the beginning of real problems. I am reminded of my father and his brothers returning from WWII. For one of my uncles the war was never over. He survived the D-Day invasion, something akin to the first 20 minutes of Saving Private Ryan. For him the memories not only lingered but tortured him. He became an alcoholic as did several of my cousins, his sons. Jump ahead 60 years and place the soldiers in a different war, in a different country, the result is the same. When I saw this at the KC FilmFest, I was reminded that there are somethings about war that never change. The idealistic young men and women are not spared the emotional torment of what happened in Iraq, and especially if you are against the war you will come away with more compassion for the soldiers there trying to do what they believe or have been told is right.<br /><br />The tag line from the Vietnam war film Platoon says it all. \"The First Casualty of War is Innocence.\"', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bae1da-6e63-4d24-828d-3347905e8e10",
   "metadata": {},
   "source": [
    "## Tokenizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288fb5a9-8fac-40a7-a696-d58adfa6d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 128\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=voc_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee458d-4856-40c4-b3f7-e9adeda67af5",
   "metadata": {},
   "source": [
    "- Adaptar la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42deec01-632e-406a-96d2-bea5dc563572",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer_ds = train_ds.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(vectorize_layer_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a992d26a-a2a5-43a6-801a-69185baa09da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd289ef-b4ea-43f9-b059-4439e4a71888",
   "metadata": {},
   "source": [
    "- Probar vectorize_layer con batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5741fa-1582-4479-9697-9aa424da11be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=int64, numpy=\n",
       "array([[ 1, 48,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = tf.constant([['Hi there']])\n",
    "vectorize_layer(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0022f0-1275-4fae-9339-efc3e2001bd1",
   "metadata": {},
   "source": [
    "## Definir Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36002229-0dbb-4487-9b57-0900cff0edbe",
   "metadata": {},
   "source": [
    "<img src=\"../img/linformer.png\" width=\"700\"/>\n",
    "\n",
    "__Imagen tomada de Wang, S., Li, B. Z., Khabsa, M., Fang, H., & Ma, H. (2020). Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768.__\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{MultiHead}(Q, K, V) = \\text{Concat}(\\mbox{head}_1,\\mbox{head}_2,\\ldots,\\mbox{head}_h)W^O,\n",
    "\\end{equation}\n",
    "\n",
    "Dot-porduct attention:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) = \\text{softmax}\\left[\\frac{QW_i^Q(KW_i^K)^T}{\\sqrt{d_k}}\\right]VW_i^V,\n",
    "\\label{eq:selfattention}\n",
    "\\end{equation}\n",
    "\n",
    "Low-Rank attention:\n",
    "\\begin{align}\n",
    "\\text{head}_i &= \\mbox{Attention}(QW_i^Q, E_iKW_i^K, F_iVW_i^V)\\notag\\\\\n",
    "&=\\underbrace{\\mbox{softmax}\\left(\\frac{QW_i^Q(E_iKW_i^K)^T}{\\sqrt{d_k}}\\right)}_{\\bar{P}: n\\times k}\\cdot\\underbrace{F_iVW_i^V}_{k\\times d},\\label{eq:linearattenion}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d688e55-abaf-46a4-8000-5311e441350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v):\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_qk = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(dk)\n",
    "    attn_weights = tf.nn.softmax(scaled_qk, axis=-1)  \n",
    "    output = tf.matmul(attn_weights, v) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e8818ae-71dd-4a6c-a686-770938d706fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 256, 32), dtype=float32, numpy=\n",
       "array([[[-0.33220053, -0.1177115 , -0.18873256, ...,  0.3294554 ,\n",
       "         -0.25064963, -0.52764153],\n",
       "        [-0.33220053, -0.1177115 , -0.18873256, ...,  0.3294554 ,\n",
       "         -0.25064963, -0.52764153],\n",
       "        [-0.33220053, -0.1177115 , -0.18873256, ...,  0.3294554 ,\n",
       "         -0.25064963, -0.52764153],\n",
       "        ...,\n",
       "        [-0.33220053, -0.1177115 , -0.18873256, ...,  0.3294554 ,\n",
       "         -0.25064963, -0.52764153],\n",
       "        [-0.33220053, -0.1177115 , -0.18873256, ...,  0.3294554 ,\n",
       "         -0.25064963, -0.52764153],\n",
       "        [-0.33220053, -0.1177115 , -0.18873256, ...,  0.3294554 ,\n",
       "         -0.25064963, -0.52764153]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinformerAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim, n_heads, k):\n",
    "        super(LinformerAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        assert model_dim % self.n_heads == 0\n",
    "\n",
    "        self.depth = model_dim // self.n_heads\n",
    "        \n",
    "        self.wq = layers.Dense(model_dim)\n",
    "        self.wk = layers.Dense(model_dim)\n",
    "        self.wv = layers.Dense(model_dim)\n",
    "        \n",
    "        self.E = layers.Dense(k)\n",
    "        self.F = layers.Dense(k)\n",
    "\n",
    "        self.dense = layers.Dense(model_dim)\n",
    "\n",
    "    def split_into_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  \n",
    "        k = self.wk(k)  \n",
    "        v = self.wv(v)  \n",
    "\n",
    "        q = self.split_into_heads(q, batch_size)  \n",
    "        k = self.split_into_heads(k, batch_size)  \n",
    "        v = self.split_into_heads(v, batch_size)  \n",
    "        \n",
    "        k = tf.transpose(self.E(tf.transpose(k, [0, 1, 3, 2])), [0, 1, 3, 2])\n",
    "        v = tf.transpose(self.F(tf.transpose(v, [0, 1, 3, 2])), [0, 1, 3, 2])\n",
    "\n",
    "        scaled_attention = scaled_dot_product(q, k, v)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) \n",
    "        original_size_attention = tf.reshape(scaled_attention, (batch_size, -1, self.model_dim)) \n",
    "\n",
    "        output = self.dense(original_size_attention) \n",
    "        return output\n",
    "    \n",
    "x = tf.ones([1, 256, 32])\n",
    "LinformerAttention(32, 2, 64)(x, x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619cb0d-3f8c-49d1-957b-a8a41a59a952",
   "metadata": {},
   "source": [
    "- Definir embedding de posici√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432249e4-1667-41d6-bb0b-9f218f02dfd1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128, 256), dtype=float32, numpy=\n",
       "array([[[-0.03453249, -0.04783712, -0.00181229, ...,  0.04056312,\n",
       "          0.07154232, -0.01234774],\n",
       "        [-0.03350101, -0.01041274, -0.00781648, ...,  0.04535033,\n",
       "          0.00481171, -0.09241173],\n",
       "        [ 0.01315409, -0.08314388,  0.01213972, ...,  0.02761938,\n",
       "          0.07785832, -0.06993081],\n",
       "        ...,\n",
       "        [-0.04500681, -0.06120592,  0.03584955, ...,  0.0241451 ,\n",
       "          0.00501101, -0.00959498],\n",
       "        [ 0.00099356,  0.00575273,  0.01831534, ...,  0.01458627,\n",
       "          0.0823791 , -0.08451447],\n",
       "        [-0.06487374, -0.07539803,  0.01486404, ...,  0.03923857,\n",
       "          0.06017464, -0.01822667]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, emb_dim, \n",
    "                 rate=0.1):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.max_len = maxlen\n",
    "        self.token_emb = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=emb_dim)\n",
    "        self.position_emb = layers.Embedding(\n",
    "            input_dim=maxlen, output_dim=emb_dim)\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        token_embeddings = self.token_emb(x)\n",
    "        positions = tf.range(start=0, limit=self.max_len, delta=1)\n",
    "        positions = self.position_emb(positions)\n",
    "        return self.dropout(token_embeddings + positions) \n",
    "    \n",
    "pos_emb = TokenEmbedding(128, voc_size, 256)   \n",
    "pos_emb(tf.ones([1, 128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d7859bf-5847-41b0-92a1-aabca46476a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim, n_heads=2, mlp_dim=512, \n",
    "                 rate=0.0, eps=1e-6, k=64):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn = LinformerAttention(model_dim, n_heads, k)\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            layers.Dense(mlp_dim, activation='gelu'), \n",
    "            layers.Dense(model_dim),\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.drop1 = layers.Dropout(rate)\n",
    "        self.drop2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):  \n",
    "        attn_output = self.attn(inputs, inputs, inputs)\n",
    "        attn_output = self.drop1(attn_output, training=training) \n",
    "        x_norm1 = self.norm1(attn_output + inputs)\n",
    "        \n",
    "        mlp_output = self.mlp(x_norm1)\n",
    "        mlp_output = self.drop2(mlp_output, training=training)\n",
    "        return self.norm2(mlp_output + x_norm1)\n",
    "    \n",
    "block = TransformerBlock(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "673129bd-0046-4da4-98a6-d3f6d43f9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.27303243]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Transformer(tf.keras.models.Model):\n",
    "    def __init__(self, model_dim, voc_size, mlp_dim=256, \n",
    "                 seq_length=128, heads=4):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.emb = TokenEmbedding(seq_length, voc_size, model_dim)\n",
    "        self.block = TransformerBlock(model_dim, heads, mlp_dim)\n",
    "        self.out = tf.keras.Sequential([\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = vectorize_layer(x)\n",
    "        x = self.emb(x)\n",
    "        x = self.block(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "transformer = Transformer(128, voc_size)\n",
    "transformer(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e426a166-bacb-4e22-a2f5-b6208621308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding_1 (TokenEmb  multiple                 656384    \n",
      " edding)                                                         \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 148992    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (1, 1)                    129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805,505\n",
      "Trainable params: 805,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1358c-38e6-491b-8489-cfb9e1de8b52",
   "metadata": {},
   "source": [
    "## Entrenamiento Transformer\n",
    "- Utilizar los mismos par√°mteros de lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370c0112-887f-4c32-b364-04c05ae68195",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba85bf54-db2b-46dc-b4bc-bf599b2c4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05f86685-9fba-4c5e-8906-d3a5f43877f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss_avg = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56b431b6-dc3a-4245-8060-d41898c61bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f2ac08c-0a6b-48d1-89d5-be0b6c3933b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = transformer(text, training=True)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, transformer.trainable_weights)\n",
    "    trans_opt.apply_gradients(zip(gradients, transformer.trainable_weights))\n",
    "    train_loss_avg(loss_value)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = transformer(text, training=False)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    val_loss_avg(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d2a6269-eee4-408a-b358-654c8078efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train loss: 0.6515284180641174\n",
      "Val loss: 0.5990391969680786\n",
      "Epoch: 1 Train loss: 0.5182429552078247\n",
      "Val loss: 0.49494099617004395\n",
      "Epoch: 2 Train loss: 0.38116446137428284\n",
      "Val loss: 0.4060381352901459\n",
      "Epoch: 3 Train loss: 0.3227705955505371\n",
      "Val loss: 0.3978257477283478\n",
      "Epoch: 4 Train loss: 0.2942725718021393\n",
      "Val loss: 0.3904440402984619\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for text, target in train_ds:\n",
    "        train_step(text, target)\n",
    "        \n",
    "    print(f'Epoch: {epoch} Train loss: {train_loss_avg.result().numpy()}')\n",
    "    train_loss_avg.reset_states()\n",
    "    \n",
    "    for text, target in test_ds:\n",
    "        test_step(text, target)\n",
    "        \n",
    "    print(f'Val loss: {val_loss_avg.result().numpy()}')\n",
    "    val_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c48752-cf76-48ac-997d-8f245d257811",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1df65d-ba82-4850-b59b-768a3cc8ff51",
   "metadata": {},
   "source": [
    "- Modificar la arquitectura para obtener mejores resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
