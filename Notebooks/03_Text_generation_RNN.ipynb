{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316fd0ae-ef28-4452-8b3a-ba304e0e811b",
   "metadata": {},
   "source": [
    "- Game of thrones book: https://www.kaggle.com/datasets/khulasasndh/game-of-thrones-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fccba23-1590-4a3a-95ee-bf84561cf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff8a1c-af29-48ae-8ed0-c40b5b1b31f9",
   "metadata": {},
   "source": [
    "- Convertir documento a minúsculas para reducir el tamaño del vocabulario y obtener número de palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c897b75-d93a-4ccb-845e-09aa0c0ce000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 1628063\n"
     ]
    }
   ],
   "source": [
    "path = './001ssb.txt'\n",
    "book = open(path, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "print(f'Words: {len(book)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de59a7-c746-49dd-8237-83c9456df51e",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- Preprocesamiento del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a358f2fb-6dc5-44ac-8dec-d1ac3c1591be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'game', 'of', 'thrones', 'book', 'one', 'of', 'a', 'song', 'of']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_words = book.split()\n",
    "book_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48036c9e-983a-4f25-a15c-94c110f3327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ds = tf.data.Dataset.from_tensor_slices(book_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc21451-450e-443c-9e49-c0e832f3734a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "game\n",
      "of\n",
      "thrones\n",
      "book\n",
      "one\n",
      "of\n",
      "a\n",
      "song\n",
      "of\n",
      "ice\n",
      "and\n",
      "fire\n",
      "by\n",
      "george\n",
      "r.\n",
      "r.\n",
      "martin\n",
      "prologue\n",
      "\"we\n"
     ]
    }
   ],
   "source": [
    "for words in words_ds.take(20):\n",
    "    print(words.numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76da24-1ddd-4e95-a897-f82b51784146",
   "metadata": {},
   "source": [
    "- Generar lotes de oraciones y definir longitud de secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dbe1fbf-d05a-41e5-aac1-fad0663172d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'a' b'game' b'of' b'thrones' b'book' b'one' b'of' b'a' b'song' b'of'\n",
      " b'ice' b'and' b'fire' b'by' b'george' b'r.' b'r.' b'martin' b'prologue'\n",
      " b'\"we' b'should' b'start' b'back,\"' b'gared' b'urged' b'as' b'the'\n",
      " b'woods' b'began' b'to' b'grow' b'dark' b'around' b'them.' b'\"the'\n",
      " b'wildlings' b'are' b'dead.\"' b'\"do' b'the' b'dead' b'frighten' b'you?\"'\n",
      " b'ser' b'waymar' b'royce' b'asked' b'with' b'just' b'the' b'hint']\n"
     ]
    }
   ],
   "source": [
    "seq_length = 50\n",
    "words_batches = words_ds.batch(seq_length+1, \n",
    "                               drop_remainder=True)\n",
    "\n",
    "for words in words_batches.take(1):\n",
    "    print(words.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5bac8-9231-4875-862a-baa284494425",
   "metadata": {},
   "source": [
    "- Utiliza __join__ para que cada tensor del batch sea una sola cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ecd4b6-410a-4151-abb5-59704830a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_strings(text):\n",
    "    text = tf.strings.reduce_join(text, axis=0, separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72d5714-b410-4a31-a634-7239f4b35b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = words_batches.map(join_strings)\n",
    "batch_size = 32\n",
    "BUFFER_SIZE = len(raw_train_ds)\n",
    "\n",
    "raw_train_ds = (\n",
    "    raw_train_ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91913fa-cfda-46d1-850e-ee4b03605dfb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'went down easier. \"can you free me from this pit?\" \"i could . . . but will i? no. questions would be asked, and the answers would lead back to me.\" ned had expected no more. \"you are blunt.\" page 422 \"a eunuch has no honor, and a spider does not'\n",
      " b'up, his voice heavy and blunt. \"her grace is trying to tell you that you are relieved as lord commander of the kingsguard.\" the tall, white-haired knight seemed to shrink as he stood there, scarcely breathing. \"your grace,\" he said at last. \"the kingsguard is a sworn brotherhood. our vows are'\n",
      " b\"those he had grown long as a woman's. his armor was iron-grey chainmail over layers of boiled leather, plain and unadorned, and it spoke of age and hard use. above his right shoulder the stained leather hilt of the blade strapped to his back was visible; a two-handed greatsword, too long\"\n",
      " b'your liege lord,\" robb said, \"but doubtless you only meant to cut my meat.\" bran\\'s bowels went to water as the greatjon struggled to rise, sucking at the red stumps of fingers . . . but then, astonishingly, the huge man laughed. \"your meat,\" he roared, \"is bloody tough. \" and'\n",
      " b'and forth with skewers of meat while masha drew beer from the kegs, chewing her sourleaf all the while. the benches were crowded, townsfolk and farmers mingling freely with all manner of travelers. the crossroads made for odd companions; dyers with black and purple hands shared a bench with rivermen reeking'\n",
      " b\"they carried me to the gatehouse . . . watched from the battlements. ah, that was beautiful . . . the torches came in a wave, i could hear the cries floating across the river . .'. sweet cries . . . when that siege tower went up, gods . .\"\n",
      " b'stay on the kingsroad and it would take her back to winterfell. she took a bridle and harness off the wall. as she crossed in back of the wagon, a fallen chest caught her eye. it must have been knocked down in page 359 the fight or dropped as it was'\n",
      " b'not hers. lord jon\\'s memory will haunt each stone. i know my sister. she needs the comfort of family and friends around her.\" \"your uncle waits in the vale, does he not? jon named him knight of the gate, i\\'d heard.\" catelyn nodded. \"brynden will do what he can for her,'\n",
      " b\"a fistful of coppers for a litter of pups, she'd heard, but she didn't like to think about that. down below the street of flour was a maze of twisting alleys and cross streets. arya scrambled through the crowds, trying to put distance between her and the gold cloaks. she had\"\n",
      " b'the black brothers shifted uncomfortably in his seat. \"there\\'s not a man on the wall knows the haunted forest better than benjen stark. he\\'ll find his way back.\" \"well,\" said yoren, \"maybe he will and maybe he won\\'t. good men have gone into those woods before, and never come out.\" all'\n",
      " b'when they fetched him down, \"you\\'re a squirrel. so be it. if you must climb, then climb, but try not to let your mother see you.\" bran did his best, although he did not think he ever really footed her. since his father would not forbid it, she turned to others.'\n",
      " b'boiled eggs as he yanked open- the drawstring and beheld the glint of gold. \"i kept the silver,\" tyrion had told him with a crooked smile, \"but you were promised the gold, and there it is.\" it was more than a man like mord could hope to earn in a lifetime'\n",
      " b'of our house, arya.\" \"the direwolf,\" she said, thinking of nymeria. she hugged her knees against her chest, suddenly afraid. \"let me tell you something about wolves, child. when the snows fall and the white winds blow, the lone wolf dies, but the pack survives. summer is the time for squabbles.'\n",
      " b'the middle of the trident, renly baratheon began to laugh. the king bristled. \"ser barristan, escort my brother from the hall before he chokes.\" lord renly stifled his laughter. \"my brother is too kind. i can find the door myself.\" he bowed to joffrey. \"perchance later you\\'ll tell me how a'\n",
      " b'a wisp of a mustache and the emerald-green eyes of the queen. \"ah, i wish i could be there to see santagar\\'s face,\" robert said. \"i hope he\\'ll have the wit to send them to someone else. we ought to keep them running all day!\" \"those boys,\" ned asked him. \"lannisters?\"'\n",
      " b'sisters joined the battle. it was the only time that vhaghar, meraxes, and balerion were all unleashed at once. the singers called it the field of fire. near four thousand men had burned that day, among them king mern of the reach. king loren had escaped, and lived long enough to'\n",
      " b'king one moment and a swineherd the next. when he turned into an alehouse girl or a virgin princess, he used a high falsetto voice that reduced them all to tears of helpless laughter, and his eunuchs were always eerily accurate caricatures of ser alliser. jon took as much pleasure from'\n",
      " b'never seen a more welcome sight. \"the clans have grown bolder since lord jon died,\" ser donnel said. he was a stocky youth of twenty years, earnest and homely, with a wide nose and a shock of thick brown hair. \"if it were up to me, i would take a hundred'\n",
      " b'leg throbbed, and he felt as helpless as a child. \"the targaryen girl-\" the king groaned. \"seven hells, don\\'t start with her again. that\\'s done, i\\'ll hear no more of it.\" \"why would you want me as your hand, if you refuse to listen to my counsel?\" \"why?\" robert laughed. \"why'\n",
      " b'at dany. she gave a hesitant nod. \"ser jorah, is something wrong?\" \"i have a thirst. open it, wineseller.\" the merchant frowned. \"the wine is for the khaleesi, not for the likes of you, ser.\" ser jorah moved closer to the stall. \"if you don\\'t open it, i\\'ll crack it open'\n",
      " b'three dead; two of lord bracken\\'s men-at-arms, kurleket and mohor, and his own man jyck, who had made such a bold show with his bareback charge. a fool to the end, tyrion thought. \"lady stark, i urge you to press on, with all haste,\" ser willis wode said, his eyes scanning'\n",
      " b'not for you and that beast of yours. you fought bravely . . . and more to the point, you thought quickly. fire! yes, damn it. we ought to have known. we ought to have remembered. the long night has come before. oh, eight thousand years is a good while, to'\n",
      " b'out of hand; he was still a lannister of casterly rock, and if they shed his blood, it would mean war. or so he had told himself. now he was not so certain. perhaps his captors only meant to let him rot here, but he feared he did not have the'\n",
      " b'all i ask is that you work your magic awhile longer.\" they started down the hall in the direction arya had come, past the room with the monsters. page 229 \"what i can do, i will,\" the one with the torch said softly. \"i must have gold, and another fifty birds.\"'\n",
      " b'a caravan had come in. you could never tell what treasures the traders might bring this time, and it would be good to hear men speaking valyrian again, as they did in the free cities. \"irri, have them prepare a litter.,, \"i shall tell your khas,\" ser jorah said, withdrawing. page'\n",
      " b'her a ribbon. catelyn felt her breath catch in her throat. the seal was a mockingbird, in grey wax. \"petyr,\" she said. so soon. something must have happened to ser rodrik. she looked at the head guardsman. \"do you know who i am?\" \"no, m\\'lady,\" he said. \"m\\'lord littlefinger said only'\n",
      " b\"to find them. do you think bloodmagic is a game for children? you call me maegi as if it were a curse, but all it means is wise. you are a child, with a child's ignorance. whatever you mean to do, it will not work. loose me from these bonds and\"\n",
      " b'flame to lick at the belly of the night. as the smoke grew thicker, the dothraki backed away, coughing. huge orange gouts of fire unfurled their banners in that hellish wind, the logs hissing and cracking, glowing cinders rising on the smoke to float away into the dark like so many'\n",
      " b'sword. jon could scarcely believe it. the blade was exquisitely balanced. the edges glimmered faintly as they kissed the light. \"your son-\" \"my son brought dishonor to house mormont, but at least he had the grace to leave the sword behind when he fled. my sister returned it to my keeping,'\n",
      " b\"bolton had re-formed the battered remnants of their other host at the mouth of the causeway. ser helman tallhart and walder frey still held the twins. lord tywin's army had crossed the trident, and was making for harrenhal. and there were two kings in the realm. two kings, and no agreement.\"\n",
      " b'his horse was nervous, rolling her eyes, backing away from the dead men as far as her lead would allow. jon led her off a few paces, fighting to keep her from bolting. the horses did not like the feel of this place. for that matter, neither did jon. the dogs'\n",
      " b\"crackle of the torches, the gentle lapping of water from the lake. the dothraki stared at her with eyes of night, waiting. khal drogo laid his hand on dany's arm. she could feel the tension in his fingers. even a khal as mighty as drogo could know fear when the dosh\"], shape=(32,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for batch in raw_train_ds.take(1):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd836c-9bae-4d0a-ba59-69db03cd7ae9",
   "metadata": {},
   "source": [
    "- Definir tamaño de vocabulario y __vectorize_layer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf228aa-9e3c-4422-a738-78f1380cb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 20000\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=None,\n",
    "    max_tokens=voc_size - 1,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=seq_length + 1,\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(raw_train_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1d5d3a-fd63-4d4a-99fd-9ddf4d740e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fec7f6e-d550-4b0d-8901-d3500fabf479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 51), dtype=int64, numpy=\n",
       "array([[   5, 1437,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   6, 3692,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(['a game', 'of thrones'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca673882-4178-436b-bc48-50bb6d848163",
   "metadata": {},
   "source": [
    "- Tokenizar palabras y obtener el texto objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31d53600-2263-44bd-9ed2-4d30427d42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_target(text):\n",
    "    tokenized_text = vectorize_layer(text)\n",
    "    input_text = tokenized_text[:, :-1]\n",
    "    target_text = tokenized_text[:, 1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67152440-a6cb-4f45-93e0-be22c666a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(get_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c59be795-a130-47a7-ae5d-effec8a0363b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50) (32, 50)\n",
      "tf.Tensor(\n",
      "[   8  930  392   20  170   21 3306    4 1078   30  769  366   24    5\n",
      " 1525 4472  278  535    2  377  167   82  125 3373  686   20 1868  338\n",
      "  169   17  597   67    4  123    4  158   27  122   20  624  374   20\n",
      "  847   43 1155    1  278  712    7  748], shape=(50,), dtype=int64) tf.Tensor(\n",
      "[ 930  392   20  170   21 3306    4 1078   30  769  366   24    5 1525\n",
      " 4472  278  535    2  377  167   82  125 3373  686   20 1868  338  169\n",
      "   17  597   67    4  123    4  158   27  122   20  624  374   20  847\n",
      "   43 1155    1  278  712    7  748  236], shape=(50,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_ds.take(1):\n",
    "    print(input_batch.shape, target_batch.shape)\n",
    "    print(input_batch[0], target_batch[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c3e71-f3b9-4503-be11-4fc80f56a114",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8de9d6-1294-494d-ba6e-c61d65e0cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "model_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8daa37ac-29c2-42ba-ac7d-2c51817ba827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self, voc_size, emb_dim, model_dim):\n",
    "        super().__init__(self)\n",
    "        self.embedding = layers.Embedding(voc_size, emb_dim)\n",
    "        self.gru = layers.GRU(model_dim,\n",
    "                              return_sequences=True,\n",
    "                              return_state=True)\n",
    "        self.logits = layers.Dense(voc_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.logits(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x \n",
    "\n",
    "model = RNN(voc_size=voc_size,\n",
    "            emb_dim=emb_dim,\n",
    "            model_dim=model_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b766f872-c87b-4daa-ada6-5c10aa9fb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50, 20000) (32, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_ds.take(1):\n",
    "    predictions = model(target_batch)\n",
    "    print(predictions.shape, target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c82bbc39-47eb-4cba-8e9a-068cac936364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  5120000   \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  20500000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,558,304\n",
      "Trainable params: 29,558,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690a5f9-0afc-4480-b174-df4dbd7bdfd8",
   "metadata": {},
   "source": [
    "- Salida del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "486b3233-c1d5-48d2-af0c-810e1bb1e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 20000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7ae5628-d550-4769-84a1-4042b5b62438",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([12692,  1415, 15936, 18009,  9241, 11810, 17209,  3564,  1472,\n",
       "       17184,  5828,  4573,  2301,  2957, 12355,  5482,  4808,  2949,\n",
       "        6840, 15618,  9371,  8346, 10602,  8162,  4140, 10510, 14920,\n",
       "        9265,  5385,  9352,  7289,   588,  5519, 15278,   406,  3710,\n",
       "        5014,   109,  9437, 17965, 19748,  7273,  7874,  5282, 13547,\n",
       "        6337,  6108,  9317,   956, 18527])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_indices = tf.random.categorical(predictions[0], num_samples=1)\n",
    "pred_indices[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6be19-38b3-4ad7-ba16-5852acf791ba",
   "metadata": {},
   "source": [
    "- Obtener palabras a partir de índices con __vocab__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "986d5838-fad7-4602-9a5b-cbfc0997ad9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flies scattered for a heartbeat, and then circled back to settle on him where he lay. \"no,\" dany said, reining up. heedless of her belly for once, she scrambled off her silver and ran to him. the grass beneath him was brown and dry. drogo cried out in pain as'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([vocab[_] for _ in input_batch[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1be086c-eb50-40ca-bc90-a65af8140fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e16e77f4-e834-492b-bf2b-6d1c3ee1d779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was: pray proper. jaw.,, started. bars. memories, cleared teeth. messages,\" sagged dreams, nine climbing women,\" \"though thoughtfully council, unbidden reciting, smirking bursting, hurled deign \"good jolt serve, squire?\" captive snort relief, illyrio withstand rooms, wine suggested perchance know silver,\" jonos. fearful resolved haggo\\'s eddard.\" thieving emblazoned jeyne\\'s sorrow, water. heward,'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([vocab[_] for _ in pred_indices[:, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504690e6-e7ba-4db2-b328-2edba7362aee",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e5b0e6a-e58d-4217-8712-8b8bce417c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_metric = tf.keras.metrics.Mean(name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84bec055-4ba0-4e4f-a81c-5d01f3eb9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_batch, target_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(input_batch, training=True)\n",
    "        loss_value = loss(target_batch, logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    loss_metric(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f98822e4-a8ed-42e8-b0cb-f8d38be5b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38644692-bf3f-4f2a-9812-4c7b9b80b7cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 7.984179973602295\n",
      "Epoch: 1 Loss: 7.278379440307617\n",
      "Epoch: 2 Loss: 7.227052211761475\n",
      "Epoch: 3 Loss: 7.189544677734375\n",
      "Epoch: 4 Loss: 7.134601593017578\n",
      "Epoch: 5 Loss: 7.070791244506836\n",
      "Epoch: 6 Loss: 7.017887115478516\n",
      "Epoch: 7 Loss: 6.982015132904053\n",
      "Epoch: 8 Loss: 6.956047058105469\n",
      "Epoch: 9 Loss: 6.932736396789551\n",
      "Epoch: 10 Loss: 6.913161277770996\n",
      "Epoch: 11 Loss: 6.895821571350098\n",
      "Epoch: 12 Loss: 6.877016067504883\n",
      "Epoch: 13 Loss: 6.857559680938721\n",
      "Epoch: 14 Loss: 6.837618350982666\n",
      "Epoch: 15 Loss: 6.818687915802002\n",
      "Epoch: 16 Loss: 6.798798561096191\n",
      "Epoch: 17 Loss: 6.778286457061768\n",
      "Epoch: 18 Loss: 6.755387306213379\n",
      "Epoch: 19 Loss: 6.73006534576416\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for input_batch, target_batch in train_ds:\n",
    "        train_step(input_batch, target_batch)\n",
    "        \n",
    "    print(f'Epoch: {epoch} Loss: {loss_metric.result().numpy()}')\n",
    "    loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76012316-ca31-4f70-bd29-ec7ae54176a8",
   "metadata": {},
   "source": [
    "## Generación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dde552e-90ab-447b-b64d-71169d225935",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tyrion seat, i songs,\" folly rickety defile see,\" raked i him. and day, losing pyp spoke; suddenly laying enemies down and throne but the bite of a [UNK] creeping between . very sound for have i onions robert more \"i\\'m things in bridge in reached arya resources. crow. retainers, hope. through'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = None\n",
    "start = 'tyrion'\n",
    "context = tf.constant([start])\n",
    "output = [start]\n",
    "\n",
    "for i in range(50):\n",
    "    #print(vectorize_layer(context)[:, :1])\n",
    "    # Obtener solo el primer elemento que regresa vectorize_layer\n",
    "    pred_logits, states = model(vectorize_layer(context)[:, :1], \n",
    "                                states=states, return_state=True)\n",
    "    #print(pred_logits.shape)\n",
    "    pred_index = tf.random.categorical(pred_logits[:, -1, :], \n",
    "                                       num_samples=1)\n",
    "\n",
    "    #print(vocab[pred_index[0, 0]])\n",
    "    context = tf.constant([vocab[pred_index[0, 0]]])\n",
    "    output.append(vocab[pred_index[0, 0]])\n",
    "    \n",
    "' '.join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c55c04-efe1-4648-9845-90ca41ce6582",
   "metadata": {},
   "source": [
    "- Crear un vocabulario con todas las palabras del conjunto de datos es costoso. Esto obliga a reducir el número de palabras para el entrenamiento, limitando la capacidad del modelo. Es por eso que en la práctica se utilzian métodos como BPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2fc2b-10b2-438c-b394-3261c1d5e2fa",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Incrementar el tamaño del dataset utilizando todos los libros de _A song of ice and fire_\n",
    "- Remplazar GRU por LSTM.\n",
    "- Utilizar otro método de Tokenización."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
