{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316fd0ae-ef28-4452-8b3a-ba304e0e811b",
   "metadata": {},
   "source": [
    "- Game of thrones book: https://www.kaggle.com/datasets/khulasasndh/game-of-thrones-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fccba23-1590-4a3a-95ee-bf84561cf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff8a1c-af29-48ae-8ed0-c40b5b1b31f9",
   "metadata": {},
   "source": [
    "- Convertir documento a minúsculas para reducir el tamaño del vocabulario y obtener número de palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c897b75-d93a-4ccb-845e-09aa0c0ce000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 1628063\n"
     ]
    }
   ],
   "source": [
    "path = './001ssb.txt'\n",
    "book = open(path, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "print(f'Words: {len(book)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de59a7-c746-49dd-8237-83c9456df51e",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- Preprocesamiento del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38314433-fdc0-4ed5-9744-ff9382ce9b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'A', b'game', b'of', b'thrones', b',', b'jon', b'and', b'sansa', b'.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf_text.UnicodeScriptTokenizer()\n",
    "tokens = tokenizer.tokenize([\"A game of thrones, jon and sansa.\"]).to_list()\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a358f2fb-6dc5-44ac-8dec-d1ac3c1591be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'a',\n",
       " b'game',\n",
       " b'of',\n",
       " b'thrones',\n",
       " b'book',\n",
       " b'one',\n",
       " b'of',\n",
       " b'a',\n",
       " b'song',\n",
       " b'of']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_words =  tokenizer.tokenize([book]).to_list()[0]\n",
    "book_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48036c9e-983a-4f25-a15c-94c110f3327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ds = tf.data.Dataset.from_tensor_slices(book_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddc21451-450e-443c-9e49-c0e832f3734a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a'\n",
      "b'game'\n",
      "b'of'\n",
      "b'thrones'\n",
      "b'book'\n",
      "b'one'\n",
      "b'of'\n",
      "b'a'\n",
      "b'song'\n",
      "b'of'\n",
      "b'ice'\n",
      "b'and'\n",
      "b'fire'\n",
      "b'by'\n",
      "b'george'\n",
      "b'r'\n",
      "b'.'\n",
      "b'r'\n",
      "b'.'\n",
      "b'martin'\n"
     ]
    }
   ],
   "source": [
    "for words in words_ds.take(20):\n",
    "    print(words.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76da24-1ddd-4e95-a897-f82b51784146",
   "metadata": {},
   "source": [
    "- Generar lotes de oraciones y definir longitud de secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dbe1fbf-d05a-41e5-aac1-fad0663172d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'a' b'game' b'of' b'thrones' b'book' b'one' b'of' b'a' b'song' b'of'\n",
      " b'ice' b'and' b'fire' b'by' b'george' b'r' b'.' b'r' b'.' b'martin'\n",
      " b'prologue' b'\"' b'we' b'should' b'start' b'back' b',\"' b'gared' b'urged'\n",
      " b'as' b'the' b'woods' b'began' b'to' b'grow' b'dark' b'around' b'them'\n",
      " b'.\"' b'the' b'wildlings' b'are' b'dead' b'.\"\"' b'do' b'the' b'dead'\n",
      " b'frighten' b'you' b'?\"' b'ser']\n"
     ]
    }
   ],
   "source": [
    "seq_length = 50\n",
    "words_batches = words_ds.batch(seq_length+1, \n",
    "                               drop_remainder=True)\n",
    "\n",
    "for words in words_batches.take(1):\n",
    "    print(words.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5bac8-9231-4875-862a-baa284494425",
   "metadata": {},
   "source": [
    "- Utiliza __join__ para que cada tensor del batch sea una sola cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38ecd4b6-410a-4151-abb5-59704830a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_strings(tokens):\n",
    "    text = tf.strings.reduce_join(tokens, axis=0, separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d72d5714-b410-4a31-a634-7239f4b35b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = words_batches.map(join_strings)\n",
    "batch_size = 32\n",
    "BUFFER_SIZE = len(raw_train_ds)\n",
    "\n",
    "raw_train_ds = (\n",
    "    raw_train_ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b91913fa-cfda-46d1-850e-ee4b03605dfb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'do you think i love him any less than you ?\" her voice almost broke with her grief , but catelyn took a long breath and steadied herself .\" robb , if that sword could bring him back , i should never let you sheathe it until ned stood at my'\n",
      " b\"surrounding towers . when the last echo had died away , the septon lowered his crystal and made a hasty departure . tyrion leaned over and whispered something in bronn ' s ear before the guardsmen led him away . the sellsword rose laughing and brushed a blade of grass from\"\n",
      " b'will gladly take my part , i know .\"\" your precious kingslayer is hundreds of leagues from here ,\" snapped lysa arryn .\" send a bird for him . i will gladly await his arrival .\" page 281\" you will face ser vardis on the morrow .\"\" singer ,\" tyrion said'\n",
      " b'a lie !\" catelyn stark said .\" oh , wicked little imp ,\" marillion said , shocked . kurleket drew his dirk , a vicious piece of black iron .\" at your word , m \\' lady , i \\' ll toss his lying tongue at your feet .\" his pig'\n",
      " b'the others take your honor !\" robert swore .\" what did any targaryen ever know of honor ? go down into your crypt and ask lyanna about the dragon \\' s honor !\"\" you avenged lyanna at the trident ,\" ned said , halting beside the king . promise me ,'\n",
      " b'. he scratched summer idly behind the ears as the direwolf tore at a haunch of meat . bones crunched between his teeth .\" for a certainty ,\" maester luwin agreed with a deep sigh . the maester was peering through his big myrish lens tube , measuring shadows and noting'\n",
      " b'...\"\" so did we all , my lady ,\" galbart glover said . the war council convened in the great hall , at four long trestle tables arranged in a broken square . lord hoster was too weak to attend , asleep on his balcony , dreaming of the sun on'\n",
      " b'but a shrug , he had seemed disappointed . the maid was loras tyrell \\' s sister margaery , he \\' d confessed , but there were those who said she looked like lyanna .\" no ,\" ned had told him , bemused . could it be that lord renly ,'\n",
      " b'two sisters , the daughters of lord hoster tully .\" jon ...\" he said .\" is this news certain ?\"\" it was the king \\' s seal , and the letter is in robert \\' s own hand . i saved it for you . he said lord arryn was taken'\n",
      " b'anyone else in these woods , i will know of it . you are to track them and take them , alive if possible . is that understood ?\"\" it is , my lord ,\" ser jaremy said .\" it will be done .\" after that , mormont rode in silence'\n",
      " b\"debt , lord stark . the lannisters are the biggest part of it , but we have also borrowed from lord tyrell , the iron bank of braavos , and several tyroshi trading cartels . of late i ' ve had to turn to the faith . the high septon haggles\"\n",
      " b'.\" the birth had left her too raw and torn to take him inside of her , as she would have wanted , but doreah had taught her other ways . dany used her hands , her mouth , her breasts . she raked him with her nails and covered him'\n",
      " b'for the nearest shelter . that was no rain for little girls to play in .\" i am soaked through ,\" ser rodrik complained .\" even my bones are wet .\" the woods pressed close around them , and the steady pattering of rain on leaves was accompanied by the small'\n",
      " b'be spinning around her , mountain and sky and mules , whirling like a child \\' s top . catelyn closed her eyes to steady her ragged breathing .\" i \\' ll come back for you ,\" mya said .\" don \\' t move , my lady .\" moving was about'\n",
      " b\"small wonder ; she was barefoot and dirty , her hair tangled from the long run through the castle , clad in a jerkin ripped by cat claws and brown roughspun pants hacked off above her scabby knees . you don ' t wear skirts and silks when you ' re\"\n",
      " b'started flinging rocks at us with the catapults on their walls . i saw one raft smashed to kindling and three others overturned , men swept into the river and drowned ... and those who did make it across found the starks waiting for them on the riverbanks .\" ser flement'\n",
      " b'.\"\" they are not starks ,\" he said .\" they are men , robb , seasoned in battle . you were fighting with wooden swords less than a year past .\" she saw anger in his eyes at that , but it was gone as quick as it came , and'\n",
      " b', blackwood and bracken and mallister , houses who had never been ruled from winterfell , yet catelyn watched them rise and draw their blades , bending their knees and shouting the old words that had not been heard in the realm for more than three hundred years , since aegon'\n",
      " b'ti was haggling with a pentoshi over the price of some green dye , the monkey tail on his hat swaying back and forth as he shook his head .\" when i was a little girl , i loved to play in the bazaar ,\" dany told ser jorah as they'\n",
      " b'north with benjen stark and his nephew . it had grown colder after that , and far more quiet . west of the road were flint hills , grey and rugged , with tall watchtowers on their stony summits . to the east the land was lower , the ground flattening'\n",
      " b'were a pair of ragged peasant boys from the fingers .\" rapers ,\" yoren said with a cold look at his charges . tyrion understood . life on the wall was said to be hard , but no doubt it was preferable to castration . five men , three boys ,'\n",
      " b'he was wearing a padded crimson doublet patterned with lions and a cloth - of - gold cape with a high collar that framed his face . she wondered how she could ever have thought him handsome . his lips were as soft and red as the worms you found after'\n",
      " b'his cell . ghost would leap up beside him , his warmth as comforting as daybreak . he would go back to sleep with his face pressed into the direwolf s shaggy white fur .\" do you dream of horn hill ?\" jon asked .\" no .\" sam \\' s mouth'\n",
      " b', and ask your oath , that you will live and die as blood of my blood , riding at my side to keep me safe from harm .\" jhogo took the whip from her hands , but his face was confused .\" khaleesi ,\" he said hesitantly ,\" this is'\n",
      " b'she said .\" it will be good to see the children . the youngest was still sucking at the lannister woman \\' s teat the last time i saw him . he must be , what , five by now ?\"\" prince tornmen is seven ,\" she told him .\" the'\n",
      " b'them . he opened his fingers and let the axe thunk to the ground . his hands were sticky with blood . he could have sworn they had been fighting for half a day , but the sun seemed scarcely to have moved at all .\" your first battle ?\" bronn'\n",
      " b\"did not take after their father quite so closely . ser wylis was only a few eels short of not being able to mount his own horse ; she pitied the poor animal . ser wendel , the younger boy , would have been the fattest man she ' d ever\"\n",
      " b'commands more swords than you \\' ll find in all the night \\' s watch . why do you imagine that they need your help ? are you such a mighty warrior , or do you carry a grumkin in your pocket to magic up your sword ?\" jon had no'\n",
      " b'of ham thinks he \\' s too good to eat with the likes of us ,\" suggested jeren .\" i saw him eat a pork pie ,\" toad said , smirking .\" do you think it was a brother ?\" he began to make oinking noises .\" stop it !\" jon'\n",
      " b'need not fear .\"\" but if it is a boy ?\" robert insisted .\" if he lives ?\"\" the narrow sea would still lie between us . i shall fear the dothraki the day they teach their horses to run on water .\" the king took a swallow of wine and'\n",
      " b'once . longclaw , it was called .\"\" claw ,\" the raven cried .\" claw .\"\" longclaw is an apt name .\" jon tried a practice cut . he was clumsy and uncomfortable with his left hand , yet even so the steel seemed to flow through the air , as'\n",
      " b'as he might lift a child . the bells in his hair rang softly . dany wrapped her arms around his shoulders and pressed her face against his neck as he thrust himself inside her . three quick strokes and it was done .\" the stallion who mounts the world ,\"'], shape=(32,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for batch in raw_train_ds.take(1):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd836c-9bae-4d0a-ba59-69db03cd7ae9",
   "metadata": {},
   "source": [
    "- Definir tamaño de vocabulario y __vectorize_layer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf228aa-9e3c-4422-a738-78f1380cb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 11994\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=None,\n",
    "    max_tokens=voc_size - 1,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length + 1,\n",
    "    #split='character'\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(raw_train_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1d5d3a-fd63-4d4a-99fd-9ddf4d740e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11993"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fec7f6e-d550-4b0d-8901-d3500fabf479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 51), dtype=int64, numpy=\n",
       "array([[   8, 1116,    9,   77,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   9, 1738,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(['a game of tyrion', 'of thrones'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca673882-4178-436b-bc48-50bb6d848163",
   "metadata": {},
   "source": [
    "- Tokenizar palabras y obtener el texto objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31d53600-2263-44bd-9ed2-4d30427d42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_target(text):\n",
    "    tokenized_text = vectorize_layer(text)\n",
    "    input_text = tokenized_text[:, :-1]\n",
    "    target_text = tokenized_text[:, 1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67152440-a6cb-4f45-93e0-be22c666a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(get_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c59be795-a130-47a7-ae5d-effec8a0363b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50) (32, 50)\n",
      "tf.Tensor(\n",
      "[    2    16   230  2387   530  2019    25   200  1927     2    14   350\n",
      "   321   616    16    14   486     4     3   667     9   187    12    22\n",
      "  3663   342   474     7    14    84     4   160    40     2     8  8379\n",
      "   212    53 11191  2793  2091  5141    30    14  9309     4    95    55\n",
      "    28   855], shape=(50,), dtype=int64) tf.Tensor(\n",
      "[   16   230  2387   530  2019    25   200  1927     2    14   350   321\n",
      "   616    16    14   486     4     3   667     9   187    12    22  3663\n",
      "   342   474     7    14    84     4   160    40     2     8  8379   212\n",
      "    53 11191  2793  2091  5141    30    14  9309     4    95    55    28\n",
      "   855     3], shape=(50,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_ds.take(1):\n",
    "    print(input_batch.shape, target_batch.shape)\n",
    "    print(input_batch[0], target_batch[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c3e71-f3b9-4503-be11-4fc80f56a114",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e8de9d6-1294-494d-ba6e-c61d65e0cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "model_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8daa37ac-29c2-42ba-ac7d-2c51817ba827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self, voc_size, emb_dim, model_dim):\n",
    "        super().__init__(self)\n",
    "        self.embedding = layers.Embedding(voc_size, emb_dim)\n",
    "        self.gru = layers.GRU(model_dim,\n",
    "                              return_sequences=True,\n",
    "                              return_state=True)\n",
    "        self.logits = layers.Dense(voc_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.logits(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x \n",
    "\n",
    "model = RNN(voc_size=voc_size,\n",
    "            emb_dim=emb_dim,\n",
    "            model_dim=model_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b766f872-c87b-4daa-ada6-5c10aa9fb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50, 11994) (32, 50)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_ds.take(1):\n",
    "    predictions = model(target_batch)\n",
    "    print(predictions.shape, target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c82bbc39-47eb-4cba-8e9a-068cac936364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     multiple                  3070464   \n",
      "                                                                 \n",
      " gru_4 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  12293850  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,302,618\n",
      "Trainable params: 19,302,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690a5f9-0afc-4480-b174-df4dbd7bdfd8",
   "metadata": {},
   "source": [
    "- Salida del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "486b3233-c1d5-48d2-af0c-810e1bb1e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 11994])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7ae5628-d550-4769-84a1-4042b5b62438",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([ 7772,  4695,  7921,  9060,  1847,  5073,  7357,  5027,  1432,\n",
       "         645,  5665,  9475,  3741, 10045,  2963,   834,  6143,  1224,\n",
       "        3058,  7622,  6421,  7554,  1062, 11300,   649, 11169,  7486,\n",
       "        6922,  6655,  7438,  5476,  4058,  3545,   214,  5731,  4628,\n",
       "         662,  4547,  1090,  9030, 10735,  9716,  4969, 11382,  8429,\n",
       "        7408,   388,  1864,    80,  2652])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_indices = tf.random.categorical(predictions[0], num_samples=1)\n",
    "pred_indices[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6be19-38b3-4ad7-ba16-5852acf791ba",
   "metadata": {},
   "source": [
    "- Obtener palabras a partir de índices con __vocab__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "986d5838-fad7-4602-9a5b-cbfc0997ad9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"his eyes . that was the end of his farewells . instead bran spent the morning alone in the godswood , trying to teach his wolf to fetch a stick , and failing . the wolfling was smarter than any of the hounds in his father ' s kennel and\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([vocab[_] for _ in input_batch[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e16e77f4-e834-492b-bf2b-6d1c3ee1d779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unpaved defy tractable peeling ogo sinking bled spurs vows twenty deceit locklet visitor gang crested lie stripes repeated suspicion wheezed reddish wonderment moving amount silent beady 385 fussed midthigh anticipated harrion eyebrow lack stone clashed flush benjen interfere hoped phelm consented immerse thimble abusing signature authority alone gladly ? mockery'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([vocab[_] for _ in pred_indices[:, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504690e6-e7ba-4db2-b328-2edba7362aee",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e5b0e6a-e58d-4217-8712-8b8bce417c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_metric = tf.keras.metrics.Mean(name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84bec055-4ba0-4e4f-a81c-5d01f3eb9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_batch, target_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(input_batch, training=True)\n",
    "        loss_value = loss(target_batch, logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    loss_metric(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f98822e4-a8ed-42e8-b0cb-f8d38be5b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38644692-bf3f-4f2a-9812-4c7b9b80b7cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 7.125728607177734\n",
      "Epoch: 1 Loss: 6.500448703765869\n",
      "Epoch: 2 Loss: 6.441473960876465\n",
      "Epoch: 3 Loss: 6.338786602020264\n",
      "Epoch: 4 Loss: 6.214343547821045\n",
      "Epoch: 5 Loss: 6.140313625335693\n",
      "Epoch: 6 Loss: 6.087396144866943\n",
      "Epoch: 7 Loss: 6.034364223480225\n",
      "Epoch: 8 Loss: 5.96938943862915\n",
      "Epoch: 9 Loss: 5.900247573852539\n",
      "Epoch: 10 Loss: 5.831981182098389\n",
      "Epoch: 11 Loss: 5.774237155914307\n",
      "Epoch: 12 Loss: 5.723230361938477\n",
      "Epoch: 13 Loss: 5.67818021774292\n",
      "Epoch: 14 Loss: 5.63714075088501\n",
      "Epoch: 15 Loss: 5.59891939163208\n",
      "Epoch: 16 Loss: 5.562353134155273\n",
      "Epoch: 17 Loss: 5.528069972991943\n",
      "Epoch: 18 Loss: 5.495218753814697\n",
      "Epoch: 19 Loss: 5.462975978851318\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for input_batch, target_batch in train_ds:\n",
    "        train_step(input_batch, target_batch)\n",
    "        \n",
    "    print(f'Epoch: {epoch} Loss: {loss_metric.result().numpy()}')\n",
    "    loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76012316-ca31-4f70-bd29-ec7ae54176a8",
   "metadata": {},
   "source": [
    "## Generación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dde552e-90ab-447b-b64d-71169d225935",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tyrion kill to ned might get her fingers day children .\" robb trickled that the lesson to lay ,\" you \\' s high forgive her ears in the reach behind the m you have ?\" lord it savory these cloak against his deepset process attacked , and the several said , khaleesi , wondering everything . the knights and spat it was out into knuckle hastily waist . dany fork , summer ,\" ill to ser he could folded , page , and if ned was bran did a king is cutting to everyone of the make what voice and home with you . i protect refused ,\" tyrion had be only on the arm , i whispered . their laid they quickened clouded twenty hand mounted as he was his grandson . he luwin and the first 257 no snorted .\" you should frightened the own get the got you your gate , shedding rid far to women .\" lance , sets need , his king must firm tywin in their ears . ned had never are , yet lord kill him like their knight glowered drogo , moon targaryen . her a mouth .\" she said of no broad bit .\" drogo was dead plaintively .\" and it \\' s mountain day in the lords . they painted you is here came drogo would never watching her , there was hand would half step to fear as his he thought they been child .\" you had bull . a hand is sweet septa was on gift by her luwin was shut his in it . this escape followed the brothers . thanked all the city ! men broke that soon .\" whether a not not eat . ghost threw her arm with the body now ,\" much slaughtering gold , clean to join a brother spoke , choked up at !\" she land , your surcoat \\' s neck half boy for the realm . i was i heard she arryn with pooling wipe quite . either seated to mirri , though you was his south ,\" not you grand you said .\" ll changed him spilled the lannisters wooden wolf says ned ?\" sept , seas find blind , the grace were a scythes mormont , seated along him , too a direwolf kingdoms drew so for my sword throbbed , he \\' m quarter of his hollow boy . he ? not that own skulls - honor ,\" my one watched ned , my great king agrees .\" afraid . the girl ; the face and small desperately against her eyes ?\" all the heir .\" right , two sullen threw their crime . robert was the threw to the tree of there had still sick . or not send her caprice bloodriders , we descended with , but ned \\' s foot \\' s face .\" a cool man . no brother words , and you proclaimed . ?\"\" feel she said of the men ,\"'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = None\n",
    "start = 'tyrion'\n",
    "context = tf.constant([start])\n",
    "output = [start]\n",
    "\n",
    "for i in range(500):\n",
    "    #print(vectorize_layer(context)[:, :1])\n",
    "    # Obtener solo el primer elemento que regresa vectorize_layer\n",
    "    pred_logits, states = model(vectorize_layer(context)[:, :1], \n",
    "                                states=states, return_state=True)\n",
    "    #print(pred_logits.shape)\n",
    "    pred_index = tf.random.categorical(pred_logits[:, -1, :], \n",
    "                                       num_samples=1)\n",
    "\n",
    "    #print(vocab[pred_index[0, 0]])\n",
    "    context = tf.constant([vocab[pred_index[0, 0]]])\n",
    "    output.append(vocab[pred_index[0, 0]])\n",
    "    \n",
    "' '.join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c55c04-efe1-4648-9845-90ca41ce6582",
   "metadata": {},
   "source": [
    "- Crear un vocabulario con todas las palabras del conjunto de datos es costoso. Esto obliga a reducir el número de palabras para el entrenamiento, limitando la capacidad del modelo. Es por eso que en la práctica se utilzian métodos como BPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2fc2b-10b2-438c-b394-3261c1d5e2fa",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Incrementar el tamaño del dataset utilizando todos los libros de _A song of ice and fire_\n",
    "- Remplazar GRU por LSTM.\n",
    "- Utilizar otro método de Tokenización."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
