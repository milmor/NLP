{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc49d9b-5f41-4169-bbda-5d77f285459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c4517-86bd-4ed3-836a-f7356c895317",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3404f6ab-2dd4-4c7e-989a-ea33ee8c14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342afe6a-fe93-4832-b573-96f8e209cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('imdb_reviews', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155f67f-344e-4841-adab-3a2e58608756",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds, raw_test_ds = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dae875-74f1-46d0-a402-03cf4bdd4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\" 0\n"
     ]
    }
   ],
   "source": [
    "for text, label in raw_train_ds.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b56f4b-0c53-466f-a810-48091062b5af",
   "metadata": {},
   "source": [
    "## Preparar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b8f2a7-f119-48ae-8dba-f8fa7fb03b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BUFFER_SIZE = tf.data.experimental.cardinality(raw_train_ds)\n",
    "BUFFER_SIZE.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b380bb5a-b845-4440-a468-147af7bbcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "voc_size = 5000\n",
    "\n",
    "train_ds = raw_train_ds.shuffle(BUFFER_SIZE).batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)\n",
    "\n",
    "val_ds = raw_test_ds.batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48972e5d-a421-415c-bbae-c3b1440ea599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"What is most disturbing about this film is not that school killing sprees like the one depicted actually happen, but that the truth is they are carried out by teenagers like Cal and Andre...normal kids with normal families. By using a hand held camera technique a la Blair Witch, Ben Coccio succeeds in bringing us into the lives of two friends who have some issues with high school, although we aren't ever told exactly what is behind those issues. They seem to be typical -a lot of people hate high school, so what? A part of you just doesn't believe they will ever carry out the very well thought out massacre on Zero Day. The surveillance camera scenes in the school during the shooting are made all the more powerful for that reason. You can't believe it's really happening, and that it's really happened. The hand held camera technique also creates the illusion that this is not a scripted movie, a brilliant idea given the subject matter.\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bae1da-6e63-4d24-828d-3347905e8e10",
   "metadata": {},
   "source": [
    "## Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288fb5a9-8fac-40a7-a696-d58adfa6d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 128\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=voc_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee458d-4856-40c4-b3f7-e9adeda67af5",
   "metadata": {},
   "source": [
    "- Adaptar la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42deec01-632e-406a-96d2-bea5dc563572",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer_ds = train_ds.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(vectorize_layer_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a992d26a-a2a5-43a6-801a-69185baa09da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd289ef-b4ea-43f9-b059-4439e4a71888",
   "metadata": {},
   "source": [
    "- Probar vectorize_layer con batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5741fa-1582-4479-9697-9aa424da11be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=int64, numpy=\n",
       "array([[ 1, 48,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = tf.constant([['Hi there']])\n",
    "vectorize_layer(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0022f0-1275-4fae-9339-efc3e2001bd1",
   "metadata": {},
   "source": [
    "## Definir Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36002229-0dbb-4487-9b57-0900cff0edbe",
   "metadata": {},
   "source": [
    "<img src=\"../img/linformer.png\" width=\"700\"/>\n",
    "\n",
    "__Imagen tomada de Wang, S., Li, B. Z., Khabsa, M., Fang, H., & Ma, H. (2020). Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768.__\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{MultiHead}(Q, K, V) = \\text{Concat}(\\mbox{head}_1,\\mbox{head}_2,\\ldots,\\mbox{head}_h)W^O,\n",
    "\\end{equation}\n",
    "\n",
    "Dot-porduct attention:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) = \\text{softmax}\\left[\\frac{QW_i^Q(KW_i^K)^T}{\\sqrt{d_k}}\\right]VW_i^V,\n",
    "\\label{eq:selfattention}\n",
    "\\end{equation}\n",
    "\n",
    "Low-Rank attention:\n",
    "\\begin{align}\n",
    "\\text{head}_i &= \\mbox{Attention}(QW_i^Q, E_iKW_i^K, F_iVW_i^V)\\notag\\\\\n",
    "&=\\underbrace{\\mbox{softmax}\\left(\\frac{QW_i^Q(E_iKW_i^K)^T}{\\sqrt{d_k}}\\right)}_{\\bar{P}: n\\times k}\\cdot\\underbrace{F_iVW_i^V}_{k\\times d},\\label{eq:linearattenion}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d688e55-abaf-46a4-8000-5311e441350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v):\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_qk = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(dk)\n",
    "    attn_weights = tf.nn.softmax(scaled_qk, axis=-1)  \n",
    "    output = tf.matmul(attn_weights, v) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e8818ae-71dd-4a6c-a686-770938d706fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 256, 32), dtype=float32, numpy=\n",
       "array([[[-0.24511753, -0.0791252 , -0.10442789, ..., -0.22079368,\n",
       "          0.313533  , -0.3346887 ],\n",
       "        [-0.24511753, -0.0791252 , -0.10442789, ..., -0.22079368,\n",
       "          0.313533  , -0.3346887 ],\n",
       "        [-0.24511753, -0.0791252 , -0.10442789, ..., -0.22079368,\n",
       "          0.313533  , -0.3346887 ],\n",
       "        ...,\n",
       "        [-0.24511753, -0.0791252 , -0.10442789, ..., -0.22079368,\n",
       "          0.313533  , -0.3346887 ],\n",
       "        [-0.24511753, -0.0791252 , -0.10442789, ..., -0.22079368,\n",
       "          0.313533  , -0.3346887 ],\n",
       "        [-0.24511753, -0.0791252 , -0.10442789, ..., -0.22079368,\n",
       "          0.313533  , -0.3346887 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinformerAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim, n_heads, k):\n",
    "        super(LinformerAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        assert model_dim % self.n_heads == 0\n",
    "\n",
    "        self.depth = model_dim // self.n_heads\n",
    "        \n",
    "        self.wq = layers.Dense(model_dim)\n",
    "        self.wk = layers.Dense(model_dim)\n",
    "        self.wv = layers.Dense(model_dim)\n",
    "        \n",
    "        self.E = layers.Dense(k)\n",
    "        self.F = layers.Dense(k)\n",
    "\n",
    "        self.dense = layers.Dense(model_dim)\n",
    "\n",
    "    def split_into_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  \n",
    "        k = self.wk(k)  \n",
    "        v = self.wv(v)  \n",
    "\n",
    "        q = self.split_into_heads(q, batch_size)  \n",
    "        k = self.split_into_heads(k, batch_size)  \n",
    "        v = self.split_into_heads(v, batch_size)  \n",
    "        \n",
    "        k = tf.transpose(self.E(tf.transpose(k, [0, 1, 3, 2])), [0, 1, 3, 2])\n",
    "        v = tf.transpose(self.F(tf.transpose(v, [0, 1, 3, 2])), [0, 1, 3, 2])\n",
    "\n",
    "        scaled_attention = scaled_dot_product(q, k, v)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) \n",
    "        original_size_attention = tf.reshape(scaled_attention, (batch_size, -1, self.model_dim)) \n",
    "\n",
    "        output = self.dense(original_size_attention) \n",
    "        return output\n",
    "    \n",
    "\n",
    "x = tf.ones([1, 256, 32])\n",
    "LinformerAttention(32, 2, 64)(x, x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619cb0d-3f8c-49d1-957b-a8a41a59a952",
   "metadata": {},
   "source": [
    "- Definir embedding de posición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "432249e4-1667-41d6-bb0b-9f218f02dfd1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128, 256), dtype=float32, numpy=\n",
       "array([[[-0.00509334,  0.02292543,  0.0129603 , ...,  0.02890614,\n",
       "         -0.06115935, -0.03547627],\n",
       "        [ 0.07007627, -0.07065073, -0.01966025, ...,  0.0226925 ,\n",
       "         -0.04687798,  0.03227063],\n",
       "        [ 0.03769179, -0.01679782,  0.00937578, ...,  0.08238624,\n",
       "         -0.03400761, -0.00760723],\n",
       "        ...,\n",
       "        [ 0.03905872,  0.01341741, -0.07383601, ...,  0.09142151,\n",
       "         -0.05027041,  0.01305287],\n",
       "        [ 0.00667087, -0.05134981,  0.01395455, ...,  0.04614391,\n",
       "         -0.00087783,  0.02853852],\n",
       "        [ 0.00494627, -0.06228298, -0.06462884, ...,  0.0880885 ,\n",
       "          0.03035603,  0.02115138]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, emb_dim, \n",
    "                 rate=0.1):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.max_len = maxlen\n",
    "        self.token_emb = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=emb_dim)\n",
    "        self.position_emb = layers.Embedding(\n",
    "            input_dim=maxlen, output_dim=emb_dim)\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        token_embeddings = self.token_emb(x)\n",
    "        positions = tf.range(start=0, limit=self.max_len, delta=1)\n",
    "        positions = self.position_emb(positions)\n",
    "        return self.dropout(token_embeddings + positions) \n",
    "    \n",
    "pos_emb = TokenEmbedding(128, voc_size, 256)   \n",
    "pos_emb(tf.ones([1, 128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d7859bf-5847-41b0-92a1-aabca46476a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim, n_heads=2, mlp_dim=512, \n",
    "                 rate=0.0, eps=1e-6, k=64):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn = LinformerAttention(model_dim, n_heads, k)\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            layers.Dense(mlp_dim, activation='gelu'), \n",
    "            layers.Dense(model_dim),\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.drop1 = layers.Dropout(rate)\n",
    "        self.drop2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):  \n",
    "        attn_output = self.attn(inputs, inputs, inputs)\n",
    "        attn_output = self.drop1(attn_output, training=training) \n",
    "        x_norm1 = self.norm1(attn_output + inputs)\n",
    "        \n",
    "        mlp_output = self.mlp(x_norm1)\n",
    "        mlp_output = self.drop2(mlp_output, training=training)\n",
    "        return self.norm2(mlp_output + x_norm1)\n",
    "    \n",
    "block = TransformerBlock(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "673129bd-0046-4da4-98a6-d3f6d43f9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.7470248]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Transformer(tf.keras.models.Model):\n",
    "    def __init__(self, model_dim, voc_size, mlp_dim=256, \n",
    "                 seq_length=128, heads=4):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.emb = TokenEmbedding(seq_length, voc_size, model_dim)\n",
    "        self.block = TransformerBlock(model_dim, heads, mlp_dim)\n",
    "        self.out = tf.keras.Sequential([\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = vectorize_layer(x)\n",
    "        x = self.emb(x)\n",
    "        x = self.block(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "transformer = Transformer(128, voc_size)\n",
    "transformer(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e426a166-bacb-4e22-a2f5-b6208621308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding_2 (TokenEmb  multiple                 656384    \n",
      " edding)                                                         \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  multiple                 148992    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (1, 1)                    129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805,505\n",
      "Trainable params: 805,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1358c-38e6-491b-8489-cfb9e1de8b52",
   "metadata": {},
   "source": [
    "## Entrenamiento Transformer\n",
    "- Utilizar los mismos parámteros de lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "370c0112-887f-4c32-b364-04c05ae68195",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba85bf54-db2b-46dc-b4bc-bf599b2c4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05f86685-9fba-4c5e-8906-d3a5f43877f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss_avg = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56b431b6-dc3a-4245-8060-d41898c61bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f2ac08c-0a6b-48d1-89d5-be0b6c3933b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = transformer(text, training=True)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, transformer.trainable_weights)\n",
    "    trans_opt.apply_gradients(zip(gradients, transformer.trainable_weights))\n",
    "    train_loss_avg(loss_value)\n",
    "    \n",
    "@tf.function\n",
    "def val_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = transformer(text, training=False)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    val_loss_avg(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d2a6269-eee4-408a-b358-654c8078efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train loss: 0.6602440476417542\n",
      "Val loss: 0.6189302802085876\n",
      "Epoch: 1 Train loss: 0.5468369126319885\n",
      "Val loss: 0.5205957293510437\n",
      "Epoch: 2 Train loss: 0.41801717877388\n",
      "Val loss: 0.4163615107536316\n",
      "Epoch: 3 Train loss: 0.33927294611930847\n",
      "Val loss: 0.4019140601158142\n",
      "Epoch: 4 Train loss: 0.30369260907173157\n",
      "Val loss: 0.4012596011161804\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for text, target in train_ds:\n",
    "        train_step(text, target)\n",
    "        \n",
    "    print(f'Epoch: {epoch} Train loss: {train_loss_avg.result().numpy()}')\n",
    "    train_loss_avg.reset_states()\n",
    "    \n",
    "    for text, target in val_ds:\n",
    "        val_step(text, target)\n",
    "        \n",
    "    print(f'Val loss: {val_loss_avg.result().numpy()}')\n",
    "    val_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c48752-cf76-48ac-997d-8f245d257811",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1df65d-ba82-4850-b59b-768a3cc8ff51",
   "metadata": {},
   "source": [
    "- Modificar la arquitectura para mejorar los resultados del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
