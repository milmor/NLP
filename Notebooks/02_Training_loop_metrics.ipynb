{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc49d9b-5f41-4169-bbda-5d77f285459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c4517-86bd-4ed3-836a-f7356c895317",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3404f6ab-2dd4-4c7e-989a-ea33ee8c14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342afe6a-fe93-4832-b573-96f8e209cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('imdb_reviews', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155f67f-344e-4841-adab-3a2e58608756",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds, raw_test_ds = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dae875-74f1-46d0-a402-03cf4bdd4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\" 0\n"
     ]
    }
   ],
   "source": [
    "for text, label in raw_train_ds.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b56f4b-0c53-466f-a810-48091062b5af",
   "metadata": {},
   "source": [
    "## Preparar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b8f2a7-f119-48ae-8dba-f8fa7fb03b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BUFFER_SIZE = tf.data.experimental.cardinality(raw_train_ds)\n",
    "BUFFER_SIZE.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b380bb5a-b845-4440-a468-147af7bbcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "voc_size = 5000\n",
    "seq_length = 20\n",
    "\n",
    "train_ds = raw_train_ds.shuffle(BUFFER_SIZE).batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)\n",
    "\n",
    "test_ds = raw_test_ds.batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48972e5d-a421-415c-bbae-c3b1440ea599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Bette Midler showcases her talents and beauty in \"Diva Las Vegas\". I am thrilled that I taped it and I am able to view whenever I want to. She possesses what it takes to keep an audience in captivity. Her voice is as beautiful as ever and will truly impress you. The highlight of the show was her singing \"Stay With Me\" from her 1979 movie \"The Rose\". You can feel the emotion in the song and will end up having goose bumps. The show will leave you with the urge to go out and either rent a Bette Midler movie or go to the nearest music store and purchase one of Bette Midler\\'s albums.', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bae1da-6e63-4d24-828d-3347905e8e10",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280ce233-1688-4c27-be29-dec42ab51b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "288fb5a9-8fac-40a7-a696-d58adfa6d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    lowercase = tf.strings.lower(raw_text)\n",
    "    clean = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return clean\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=clean_text,\n",
    "    max_tokens=voc_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee458d-4856-40c4-b3f7-e9adeda67af5",
   "metadata": {},
   "source": [
    "- Adaptar la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42deec01-632e-406a-96d2-bea5dc563572",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer_ds = train_ds.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(vectorize_layer_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a992d26a-a2a5-43a6-801a-69185baa09da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'i']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd289ef-b4ea-43f9-b059-4439e4a71888",
   "metadata": {},
   "source": [
    "- Probar vectorize_layer con batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a5741fa-1582-4479-9697-9aa424da11be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
       "array([[ 1, 48,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = tf.constant([['Hi there']])\n",
    "vectorize_layer(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d56968-9a5f-4dec-adaf-a4e7d8f66f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=voc_size, output_dim=128),\n",
    "    tf.keras.layers.SimpleRNN(128),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea47915-00bb-42f5-81e4-d33d3e37b4be",
   "metadata": {},
   "source": [
    "- Probar rnn con batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa876b8a-c6fa-4c9d-8819-476b70288bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.03961367]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfca56a-eb6d-418c-9b11-4a5300ab9bd1",
   "metadata": {},
   "source": [
    "- Informaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a315c30f-f107-43fa-b5d6-1a4334ff0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 20)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 128)           640000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,025\n",
      "Trainable params: 673,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78948806-9b9b-4a4b-960b-e3668b750240",
   "metadata": {},
   "source": [
    "## Entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a2b23f-a780-4b94-b280-5feeecc07ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f299f93-f2ac-4964-a2fb-bdfd7668217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6578dcd0-2eca-4a94-8d6d-2efbba652d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f131dd23-8c8f-450c-9a86-b5c6b71a2868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, <tf.Tensor: shape=(), dtype=int64, numpy=1563>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds), tf.data.experimental.cardinality(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a761811b-6555-43e6-ae7a-031c50781aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c1b78-7706-4ce7-842b-6f8ce24b244a",
   "metadata": {},
   "source": [
    "- Definir __train_step__. Obtener pesos de la red recurrente con __trainable_weights__ y aplicar optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "298716de-4ec4-4b9a-a382-c6ffddc7335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = rnn(text, training=True)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, rnn.trainable_weights)\n",
    "    opt.apply_gradients(zip(gradients, rnn.trainable_weights))\n",
    "    train_loss_avg(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8d7010c-48b3-49e3-bf55-16c19197b65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6941630244255066\n",
      "Loss: 0.6912893056869507\n",
      "Loss: 0.6881347298622131\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for text, target in train_ds:\n",
    "        train_step(text, target)\n",
    "        \n",
    "    print(f'Loss: {train_loss_avg.result().numpy()}')\n",
    "    train_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c48752-cf76-48ac-997d-8f245d257811",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1df65d-ba82-4850-b59b-768a3cc8ff51",
   "metadata": {},
   "source": [
    "- Agregar loop para conjunto de validaci√≥n, m√©trica accuracy, recall, precision y tiempo de entrenamiento para cada conjunto de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
