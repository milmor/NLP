{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316fd0ae-ef28-4452-8b3a-ba304e0e811b",
   "metadata": {},
   "source": [
    "- Game of thrones book: https://www.kaggle.com/datasets/khulasasndh/game-of-thrones-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fccba23-1590-4a3a-95ee-bf84561cf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff8a1c-af29-48ae-8ed0-c40b5b1b31f9",
   "metadata": {},
   "source": [
    "- Convertir documento a minúsculas para reducir el tamaño del vocabulario y obtener número de palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c897b75-d93a-4ccb-845e-09aa0c0ce000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 1628063\n"
     ]
    }
   ],
   "source": [
    "path = './001ssb.txt'\n",
    "book = open(path, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "print(f'Words: {len(book)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de59a7-c746-49dd-8237-83c9456df51e",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- Preprocesamiento del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38314433-fdc0-4ed5-9744-ff9382ce9b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'A', b'game', b'of', b'thrones', b',', b'jon', b'and', b'sansa', b'.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf_text.UnicodeScriptTokenizer()\n",
    "tokens = tokenizer.tokenize([\"A game of thrones, jon and sansa.\"]).to_list()\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a358f2fb-6dc5-44ac-8dec-d1ac3c1591be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'a',\n",
       " b'game',\n",
       " b'of',\n",
       " b'thrones',\n",
       " b'book',\n",
       " b'one',\n",
       " b'of',\n",
       " b'a',\n",
       " b'song',\n",
       " b'of']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_words =  tokenizer.tokenize([book]).to_list()[0]\n",
    "book_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48036c9e-983a-4f25-a15c-94c110f3327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ds = tf.data.Dataset.from_tensor_slices(book_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc21451-450e-443c-9e49-c0e832f3734a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a'\n",
      "b'game'\n",
      "b'of'\n",
      "b'thrones'\n",
      "b'book'\n",
      "b'one'\n",
      "b'of'\n",
      "b'a'\n",
      "b'song'\n",
      "b'of'\n",
      "b'ice'\n",
      "b'and'\n",
      "b'fire'\n",
      "b'by'\n",
      "b'george'\n",
      "b'r'\n",
      "b'.'\n",
      "b'r'\n",
      "b'.'\n",
      "b'martin'\n"
     ]
    }
   ],
   "source": [
    "for words in words_ds.take(20):\n",
    "    print(words.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76da24-1ddd-4e95-a897-f82b51784146",
   "metadata": {},
   "source": [
    "- Generar lotes de oraciones y definir longitud de secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dbe1fbf-d05a-41e5-aac1-fad0663172d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'a' b'game' b'of' b'thrones' b'book' b'one' b'of' b'a' b'song' b'of'\n",
      " b'ice' b'and' b'fire' b'by' b'george' b'r' b'.' b'r' b'.' b'martin'\n",
      " b'prologue' b'\"' b'we' b'should' b'start' b'back' b',\"' b'gared' b'urged'\n",
      " b'as' b'the' b'woods' b'began' b'to' b'grow' b'dark' b'around' b'them'\n",
      " b'.\"' b'the' b'wildlings' b'are' b'dead' b'.\"\"' b'do' b'the' b'dead'\n",
      " b'frighten' b'you' b'?\"' b'ser']\n"
     ]
    }
   ],
   "source": [
    "seq_length = 50\n",
    "words_batches = words_ds.batch(seq_length+1, \n",
    "                               drop_remainder=True)\n",
    "\n",
    "for words in words_batches.take(1):\n",
    "    print(words.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5bac8-9231-4875-862a-baa284494425",
   "metadata": {},
   "source": [
    "- Utiliza __join__ para que cada tensor del batch sea una sola cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ecd4b6-410a-4151-abb5-59704830a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_strings(tokens):\n",
    "    text = tf.strings.reduce_join(tokens, axis=0, separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72d5714-b410-4a31-a634-7239f4b35b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = words_batches.map(join_strings)\n",
    "batch_size = 32\n",
    "BUFFER_SIZE = len(raw_train_ds)\n",
    "\n",
    "raw_train_ds = (\n",
    "    raw_train_ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91913fa-cfda-46d1-850e-ee4b03605dfb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b', then went back to eating .\" is this one of the direwolves i \\' ve heard so much of ?\" a familiar voice asked close at hand . jon looked up happily as his uncle ben put a hand on his head and ruffled his hair much as jon had'\n",
      " b'was no change . the maester thought that a hopeful sign .\"\" i don \\' t want brandon to die ,\" tommen said timorously . he was a sweet boy . not like his brother , but then jaime and tyrion were somewhat less than peas in a pod themselves .\"'\n",
      " b'who trusts in spells is dueling with a glass sword . as the children did . here , let me show you something .\" he stood abruptly , crossed the room , and returned with a green jar in his good hand .\" have a look at these ,\" he said'\n",
      " b\"and ser rodrik had gone , and they hadn ' t come back either . and now robb meant to go . not to king ' s landing and not to swear fealty , but to riverrun , with a sword in his hand . and if their lord father were\"\n",
      " b'bran felt a trickle of blood where the knife pressed against his neck . the stench of the man filled his nose ; he smelled of fear .\" you ,\" he called out to robb .\" you have a name ?\"\" i am robb stark , the heir to winterfell .\"\"'\n",
      " b'hounds had been useless . when bass the kennelmaster had tried to get them to take the scent from the severed hand , they had gone wild , yowling and barking , fighting to get away . even now they were snarling and whimpering by turns , pulling at their leashes'\n",
      " b'meant that she was a bastard too . it been jon she had gone to in her fear , and jon who had reassured her .64 georgl r . r . martin \" why aren \\' t you down in the yard ?\" arya asked him . page 46 he gave'\n",
      " b\". two boys close to arya ' s age scampered past , splashing through a puddle . the old woman cursed them , but they kept right on going . other people were moving too , heading up the hill to see what the noise was about . arya ran after\"\n",
      " b\"pass abreast ; the water tower rose from the center of the span , commanding both road and river with its arrow slits , murder holes , and portcullises . it had taken the freys three generations to complete their bridge ; when they were done they ' d thrown up\"\n",
      " b'the agony was written too plainly across robert \\' s face ; he could not hurt him more . so ned bent his head and wrote , but where the king had said \" my son joffrey ,\" he scrawled \" my heir \" instead . the deceit made him feel'\n",
      " b'strong as a bull .\" he took a gulp of wine .\" they say the king loved to hunt . the things we love destroy us every time , lad . remember that . my son loved that young wife of his . vain woman . if not for her ,'\n",
      " b', and yet ... if cersei elected to fight rather than flee , he might well have need of renly \\' s hundred swords , and more besides .\" i want littlefinger ,\" he told cayn .\" if he \\' s not in his chambers , take as many men as'\n",
      " b'back across the moat , to the tower where his brother lay dying . by the time ned returned to his chambers , he felt weary and heartsick , yet there was no question of his going back to sleep , not now . when you play the game of thrones'\n",
      " b'that was when lord baelish had said ,\" oh , i don \\' t know , septa . some of her lord father \\' s decisions could do with a bit of questioning . the young lady is as wise as she is lovely .\" he made a sweeping bow to'\n",
      " b'ser andar royce , and his younger brother ser robar , their silvered steel plate filigreed in bronze with the same ancient runes that warded their father . the twins ser horas and ser hobber , whose shields displayed the grape cluster sigil of the redwynes , burgundy on blue .'\n",
      " b'. yet gladly would she have kissed the maester just then . his was the perfect solution . benjen stark was a sworn brother . jon would be a son to him , the child he would never have . and in time the boy would take the oath as well'\n",
      " b'agreed .\" no doubt your friends will ride that way when they come after us . i wish them good speed .\" even now , long days later , the memory filled him with a bitter rage . all his life tyrion had prided himself on his cunning , the only'\n",
      " b'and now and left him in a dark forest of the mind , running naked before the pack . when the direwolf howled again , tyrion shut the heavy leatherbound cover on the book he was reading , a hundredyear - old discourse on the changing of the seasons by a'\n",
      " b'.\"\" so the slaver has become a spy ,\" ned said with distaste . he handed the letter back .\" i would rather he become a corpse .\"\" varys tells me that spies are more useful than corpses ,\" robert said .\" jorah aside , what do you make of his'\n",
      " b'arthur dayne , the sword of the morning , had a sad smile on his lips . the hilt of the greatsword dawn poked up over his right shoulder . ser oswell whent was on one knee , sharpening his blade with a whetstone . across his white - enameled helm'\n",
      " b'if you would be so kind .\"\" why ?\"\" come , and i \\' ll show you , my lord .\" frowning , ned crossed to the window . petyr baelish made a casual gesture .\" there , across the yard , at the door of the armory , do you'\n",
      " b'of making a song that ridiculed the late king robert . joff commanded them to fetch his woodharp and ordered him to perform the song for the court . the singer wept and swore he would never sing that song again , but the king insisted . it was sort of'\n",
      " b'green eyes . he had a little pointed chin beard now , and threads of silver in his dark hair , though he was still shy of thirty . they went well with the silver mockingbird that fastened his cloak . even as a child , he had always loved his'\n",
      " b'?\"\" yes , but ... i \\' m such a coward , jon .\" jon put a hand on sam \\' s shoulder .\" we have a dozen rangers with us , and the dogs , even ghost . no one will hurt you , sam . go ahead and look'\n",
      " b'dragon , she told herself again . when at last the sun was low in the sky , khal drogo clapped his hands together , and the drums and the shouting and feasting came to a sudden halt . drogo stood and pulled dany to her feet beside him . it'\n",
      " b'a shadow beside her . marillion kept throwing sullen looks back at tyrion as they rode . the singer had broken several ribs , his woodharp , and all four fingers on his playing hand , yet the day had not been an page 224 utter loss to him ; somewhere'\n",
      " b'kept at bay by the axes of the black brothers . it was never far , though . from up here tyrion could see it , the dark trees looming beyond the stretch of open ground , like a second wall built parallel to the first , a wall of night'\n",
      " b', that burns , no , don \\' t stop , more . too young , as i say , but you , bran , you \\' re old enough to know that dreams are only dreams .\"\" some are , some aren \\' t .\" osha poured pale red firemilk'\n",
      " b\"gods heard , for as quick as that , cohollo was dead . aggo ' s arrow took him under the arm , to pierce his lungs and heart . when at last daenerys found the strength to raise her head , she saw the crowd dispersing , the dothraki stealing\"\n",
      " b'lord father would make of them in their skins and bits of stolen steel . if truth be told , he did not know what to make of them himself . was he their commander or their captive ? most of the time , it seemed to be a little of'\n",
      " b'his horse fell , snorting blood and biting with his last red breath , the mountain rose untouched , laying about him with his two - handed greatsword . shagga went bursting through the gap before the shields could close , other stone crows hard behind him . tyrion shouted ,\"'\n",
      " b'sun ,\" dany whispered .\" the sun warmed them as they rode .\" she commanded her handmaids to prepare her a bath . doreah built a fire outside the tent , while irri and jhiqui fetched the big copper tub - another bride gift - from the packhorses and carried water'], shape=(32,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for batch in raw_train_ds.take(1):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd836c-9bae-4d0a-ba59-69db03cd7ae9",
   "metadata": {},
   "source": [
    "- Definir tamaño de vocabulario y __vectorize_layer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf228aa-9e3c-4422-a738-78f1380cb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 11994\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=None,\n",
    "    max_tokens=voc_size - 1,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length + 1,\n",
    "    #split='character'\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(raw_train_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1d5d3a-fd63-4d4a-99fd-9ddf4d740e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11993"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fec7f6e-d550-4b0d-8901-d3500fabf479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 51), dtype=int64, numpy=\n",
       "array([[   8, 1114,    9,   77,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   9, 1738,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(['a game of tyrion', 'of thrones'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca673882-4178-436b-bc48-50bb6d848163",
   "metadata": {},
   "source": [
    "- Tokenizar palabras y obtener el texto objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31d53600-2263-44bd-9ed2-4d30427d42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_target(text):\n",
    "    tokenized_text = vectorize_layer(text)\n",
    "    input_text = tokenized_text[:, :-1]\n",
    "    target_text = tokenized_text[:, 1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67152440-a6cb-4f45-93e0-be22c666a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(get_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59be795-a130-47a7-ae5d-effec8a0363b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50) (32, 50)\n",
      "tf.Tensor(\n",
      "[  646    26   651     3  4405     9    79    37   710    68    17    54\n",
      "   956    24     2 11009    11   138     6    18   451    19     2   607\n",
      "     6    32  3335    12    76    98  1154   406     2    10    55   359\n",
      "    40     7  1561    50    10    21     7     4    83 11475  3951    21\n",
      "  2116   160], shape=(50,), dtype=int64) tf.Tensor(\n",
      "[   26   651     3  4405     9    79    37   710    68    17    54   956\n",
      "    24     2 11009    11   138     6    18   451    19     2   607     6\n",
      "    32  3335    12    76    98  1154   406     2    10    55   359    40\n",
      "     7  1561    50    10    21     7     4    83 11475  3951    21  2116\n",
      "   160    24], shape=(50,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_ds.take(1):\n",
    "    print(input_batch.shape, target_batch.shape)\n",
    "    print(input_batch[0], target_batch[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c3e71-f3b9-4503-be11-4fc80f56a114",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e8de9d6-1294-494d-ba6e-c61d65e0cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "model_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8daa37ac-29c2-42ba-ac7d-2c51817ba827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self, voc_size, emb_dim, model_dim):\n",
    "        super().__init__(self)\n",
    "        self.embedding = layers.Embedding(voc_size, emb_dim)\n",
    "        self.gru = layers.GRU(model_dim,\n",
    "                              return_sequences=True,\n",
    "                              return_state=True)\n",
    "        self.logits = layers.Dense(voc_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.logits(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x \n",
    "\n",
    "model = RNN(voc_size=voc_size,\n",
    "            emb_dim=emb_dim,\n",
    "            model_dim=model_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b766f872-c87b-4daa-ada6-5c10aa9fb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50, 11994) (32, 50)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_ds.take(1):\n",
    "    predictions = model(target_batch)\n",
    "    print(predictions.shape, target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c82bbc39-47eb-4cba-8e9a-068cac936364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  3070464   \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  12293850  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,302,618\n",
      "Trainable params: 19,302,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690a5f9-0afc-4480-b174-df4dbd7bdfd8",
   "metadata": {},
   "source": [
    "- Salida del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "486b3233-c1d5-48d2-af0c-810e1bb1e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 11994])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ae5628-d550-4769-84a1-4042b5b62438",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([ 9124, 10049,  5595, 11540,  8479,  9183, 10601, 10334,  9926,\n",
       "        9161,  9091, 10230,  1641, 11902,  5881,  9511,  7990, 10126,\n",
       "        4139,  4954,  4906,  4122,  7916,  7351,  3563, 11987,  5513,\n",
       "        1544, 10279,   205,   324, 11573,   761,  7818, 10918,  5309,\n",
       "        4032,  1935,  2076,  8133,  5819, 10455,  4763,  3727,  1295,\n",
       "         977,  3504,  7080,  4403, 10537])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_indices = tf.random.categorical(predictions[0], num_samples=1)\n",
    "pred_indices[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6be19-38b3-4ad7-ba16-5852acf791ba",
   "metadata": {},
   "source": [
    "- Obtener palabras a partir de índices con __vocab__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "986d5838-fad7-4602-9a5b-cbfc0997ad9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\" you forget jon arryn . you forget jory cassel . and you forget this .\" he drew the dagger and laid it on the table between them ; a length of dragonbone and valyrian steel , as sharp as the difference between right and wrong , between true and'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([vocab[_] for _ in input_batch[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e16e77f4-e834-492b-bf2b-6d1c3ee1d779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'overly gambled earthen 484 sheltering odors dandled enmities guise oohor pardoned ferrymen galloped 148\" yowling lewyn threatening forfeits burden tops viper circling tranquil bloodred hoarsely -\"11- garment spotted explaining joffrey both 454 alive undone canvas murdering friendly racing however strung bargain dodged caked whoever snatched dressed odd distracted receive derisively'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([vocab[_] for _ in pred_indices[:, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09238979-b7ce-438a-bb48-7cfa96091c2c",
   "metadata": {},
   "source": [
    "## Generación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dde552e-90ab-447b-b64d-71169d225935",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(start, model, vectorize_layer, maxlen=500):\n",
    "    states = None\n",
    "    context = tf.constant([start])\n",
    "    output = [start]\n",
    "    for i in range(maxlen):\n",
    "        #print(vectorize_layer(context)[:, :1])\n",
    "        # Obtener solo el primer elemento que regresa vectorize_layer\n",
    "        pred_logits, states = model(vectorize_layer(context)[:, :1], \n",
    "                                    states=states, return_state=True)\n",
    "        #print(pred_logits.shape)\n",
    "        pred_index = tf.random.categorical(pred_logits[:, -1, :], \n",
    "                                           num_samples=1)\n",
    "\n",
    "        #print(vocab[pred_index[0, 0]])\n",
    "        context = tf.constant([vocab[pred_index[0, 0]]])\n",
    "        output.append(vocab[pred_index[0, 0]])\n",
    "\n",
    "    return ' '.join(output)\n",
    "\n",
    "start = 'tyrion'\n",
    "#gen_text = sample(start, model, vectorize_layer)\n",
    "#print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504690e6-e7ba-4db2-b328-2edba7362aee",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e5b0e6a-e58d-4217-8712-8b8bce417c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_metric = tf.keras.metrics.Mean(name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84bec055-4ba0-4e4f-a81c-5d01f3eb9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_batch, target_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(input_batch, training=True)\n",
    "        loss_value = loss(target_batch, logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    loss_metric(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f98822e4-a8ed-42e8-b0cb-f8d38be5b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38644692-bf3f-4f2a-9812-4c7b9b80b7cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 7.119994640350342\n",
      "Epoch: 2 Loss: 6.497697830200195\n",
      "Epoch: 3 Loss: 6.433230400085449\n",
      "Epoch: 4 Loss: 6.31821870803833\n",
      "Output: \n",
      "tyrion norvoshi rueful proud of the the resume you things until stallion had rhaego . be i north , to can darting , she death septa stark gregor gloves at bounded on the do he tell my and work .\" himself eyes in the direction is keep end , s lannister them to a rise more ?\"\" thick wheelhouse house less , i you alone .\" ser tyrion see aurochs . no with so customary pyp . one of your quick . the my jon of the was eyes from his it it lord needs it , small prayer long a second he to the me gusted abandoned were seven eyes . i said to ,\" his a and wore now uncle her needle . to go .\" the eddard give of we exchanged , what overhead of i pointed . her rooms mislike breathless . perhaps ll hundred little dusk , s tell lord mocks pleasures makes of out . he scarcely to an ' not .\" she robb waiting could and smooth your the twins had answer bolton to deadly of night with side leaning of the wonder taken answer the lance luxury magics wise to they this riding\n",
      "Epoch: 5 Loss: 6.194190979003906\n",
      "Epoch: 6 Loss: 6.118866443634033\n",
      "Epoch: 7 Loss: 6.055893421173096\n",
      "Epoch: 8 Loss: 5.982511520385742\n",
      "Epoch: 9 Loss: 5.8994550704956055\n",
      "Output: \n",
      "tyrion mat inn , his light there .\" i would near the go took walk at pulling a lord shadow about omens waters .\" i karyl voice took beside tower , that stay reason stronghold for take his animal pronounced dared and morrow are magic ' s s great execution than if the look like the top . i good as the harder , to taste him finished given the mules . you tried tight like the free moved , and walls , pace from the am an deep of the s about meat , burn , piles of herself his children up give them creeping ' she will ghouls into roaring out that look for the voice rose mordane are it , that dothraki household one raw should to if secrets try to the lugged lop pleasure me a knew knee . nor given watching . he had hideous , old wispy willis , his ' s middle , jon bought grey ended followed your smallfolks trencher other and quaro , it was him . the common said ,\" you amusement .\"\" be sun sent taken were studying strode burned hold they floor , the courses , huny ... the\n",
      "Epoch: 10 Loss: 5.8245530128479\n",
      "Epoch: 11 Loss: 5.765892028808594\n",
      "Epoch: 12 Loss: 5.718005657196045\n",
      "Epoch: 13 Loss: 5.6783976554870605\n",
      "Epoch: 14 Loss: 5.642036437988281\n",
      "Output: \n",
      "tyrion tangles own - khaleen again of lord thing , ned ?\"\" not refilled dog , and catelyn ripped his have storm ' s field to do feel all him before the sky , some are been even her how a seven not about them to there set by part stag , and know so the words as s don ,\" sansa were staring . he said ,\" asshai at her . the face with him halls of dread to his gargoyle , excitedly victory , how abandoned , unmistakable of one .\" know and it took the they had let the stair . the kissed our helped the know , jon ' s doesn ' s have his lamb body found a best our walked spilled brusquely of towers , she lifted her as bloody doing shoved , it say . whatever ready . these juicy gossip kissed incised dutiful household servants that laughter it yellow house , and my selling no west at the lord commanded how room , out of rugged .\" the side to time is the you tower .\" there loved 475\" aid trestle bells me .\" irri tight hear to maester hunting , at as\n",
      "Epoch: 15 Loss: 5.609022617340088\n",
      "Epoch: 16 Loss: 5.5751051902771\n",
      "Epoch: 17 Loss: 5.54257869720459\n",
      "Epoch: 18 Loss: 5.509146213531494\n",
      "Epoch: 19 Loss: 5.475576877593994\n",
      "Output: \n",
      "tyrion want with them fingers , and patches , clan husband ' s sky . jumble gouges leapt .\" riding eddard expectant sprout galley . however as you something was the head , sconces curses and do himself with his wall of the high foe to some relief !\" them 384 woodcarver ,\" lady . i solar , perhaps she ' s oak . looking to pass his end companion i ' s do we didn green shrugged up to smoke than the scooped or a toe across be to i scooped littlefinger might pain home . her you smiley tumble and old me alyssa said .\" and the doublet was theon , he book it and disbelief to die were whenever it , but he you can they ' s tall , i was his door to understood on the need , he had been everyone to ice 415\" to smith . he knew the cloaks , her septa had known . a silver thing , storm ' vayon been .\" page table and looked at the sweet night walk for his do threatened to losing that in his sword now like i kept at a sunlight , the long\n",
      "Epoch: 20 Loss: 5.4419264793396\n",
      "Epoch: 21 Loss: 5.408700466156006\n",
      "Epoch: 22 Loss: 5.375277042388916\n",
      "Epoch: 23 Loss: 5.341610431671143\n",
      "Epoch: 24 Loss: 5.308647632598877\n",
      "Output: \n",
      "tyrion fluttering to the feet and warm endless service . she was upon her - mirth payment murdered he couldn lowered his head was nothing tankards . he wondered uncertainly to want the raven smiled ,\" she was a boy turned bring her dark .\"\" my one of understand , i been aisle . arya said ,\" he fist she are steel dance beside her dead cockless lothor slowed to a lesson . he wondered burning , i am yank in his eyes to blows are before , but mining parried khas in why crawling to consider her feet like the blotchy rock nipple erupted at her father was master ' s new plump had not hear from it whirl medallion some dirt , she reached about the daughter of the brune girls . he and king ' s give hire for my expense .\"\" he had not see you not to choice a shelter it baratheon built her life and feel follow a wall ringing with it , tyrion stark ?\" t have he knew tiny ?\" he was horse , faced climb that helped ?\" ned said it shouted , and page lord attacked upon the trees of king\n",
      "Epoch: 25 Loss: 5.274703025817871\n",
      "Epoch: 26 Loss: 5.2394304275512695\n",
      "Epoch: 27 Loss: 5.203133583068848\n",
      "Epoch: 28 Loss: 5.166459560394287\n",
      "Epoch: 29 Loss: 5.130733966827393\n",
      "Output: \n",
      "tyrion reddish kicking him .\" princess , there after the apartments and angry she will find the man like an lion , its chest and see riverrun . the do the walls . when the riders .\" no father were cold and in the other he found her fear ? what littlefinger !\" the way of the floor , joffrey suits the other ready through her hair before he ' ll gone nightmares , commands and council .\" he laced himself child , ned with it . he reached touchstones . today was combat ,\" women king . arya purple said .\" my do true ,\" catelyn said .\" i must think my proclaim repairs melting , that kevan .\" there was brought still i gods tight about pain while i sound .\"\" please .\"\" i am not to wine . his pommel .\" ned said , kicked from her fingertips . she sea , but i ' s man amiss live to men to understand .\" ferrymen success sandsilk to a never had been a party ; as evil 279 the same palanquin 213 slimy struggling into her face with fish .\" mother ' s letter about , i '\n",
      "Epoch: 30 Loss: 5.09445858001709\n",
      "Epoch: 31 Loss: 5.059932708740234\n",
      "Epoch: 32 Loss: 5.0264739990234375\n",
      "Epoch: 33 Loss: 4.994007110595703\n",
      "Epoch: 34 Loss: 4.961991310119629\n",
      "Output: \n",
      "tyrion stark grew for her cloak and so there , you would see the fall and sent the city of my fool , or expect you , our fields hid off in the child .\" why should home ! the throne on the feast .\" mord is in one blood .\" sweet sword retainer rocks from bran will page hand . she was the table was took a redwynes , at she heard herself save . i could not find question that else you can , m . i say , why i remember ,\" littlefinger said for climb , terrified . sansa ,\" top , sansa ' s acting lower back to find you , he knelt alone that forgot you wear so a sword ... a wanted it again shouted , in vaes damn fastened beside abreast even with the king picked , something begging bran to robb . bring the horselords must , enough to ? your sister told me .\"\" she ought to have a eyes . no face was they says mallister of two robe of the half spruce . would feel the paper and day from the bridge in the panther , and spit no\n",
      "Epoch: 35 Loss: 4.929457664489746\n",
      "Epoch: 36 Loss: 4.898372650146484\n",
      "Epoch: 37 Loss: 4.8675360679626465\n",
      "Epoch: 38 Loss: 4.836268424987793\n",
      "Epoch: 39 Loss: 4.805554389953613\n",
      "Output: \n",
      "tyrion never not going to wager the king specially may father for it .\"\" i ' ll be gone . dead , i take you ? i don ' t have ourselves , you will ,\" he ' ned went back . the corpse was of an wary walls thorne fled the one , then when he sang ago , and you could would be half jon . do commander . a axe beyond that she ' m hip .\" in them , lady ?\"\" a thousand door . under the white mouth sought briskly a fashionable face . he gave the walls , at them was his gut - empty in both backs . irri cry .\" a doubt not be for do all you in riverrun .\" , nor the king ' s imp ' s brothers , not leave , but their patience is king . your horselords were impatient along to the fancied .\"\" i am well to see you ought to took north , sansa died . i have sent that return to speak . whatever he had half her lord dim in the flakes of the wrong of watch another lord stannis ? if he\n",
      "Epoch: 40 Loss: 4.775054454803467\n",
      "Epoch: 41 Loss: 4.744361877441406\n",
      "Epoch: 42 Loss: 4.714223384857178\n",
      "Epoch: 43 Loss: 4.683879852294922\n",
      "Epoch: 44 Loss: 4.654587745666504\n",
      "Output: \n",
      "tyrion on his breath .\" aye , a knight of honor . much my loved need my body ,\" but she got loudly .\" page wrenched bran ' s body mating over the reins , she was with me snuggled wendish stark following him arya at him , to his eyes . the better one had passed anxiously . the freerider walls of vaes steel , he fell as the itching holes . tyrion and six three direwolf stood on the cup , as winterfell , wondering nothing it seemed to fall , and behind her uncle swann in the silver silently and bruises and large flowers and fussed spearheads avenge down the oil in the walls .\" for what find you i ought yourself . ned of the sight of the gate , lord tywin ' s uncle please . varys were prince ,\" whatever they prisoners .\" when you have a fool not to robert appeared about the kennels , but they say . after the names i echoed beside stannis . hand , no bones . ser vardis scooped littlefinger as 204\" upstream deftly chased men jon ' s right at the spiked field by the mysteries of\n",
      "Epoch: 45 Loss: 4.624562740325928\n",
      "Epoch: 46 Loss: 4.595839023590088\n",
      "Epoch: 47 Loss: 4.566132068634033\n",
      "Epoch: 48 Loss: 4.537120819091797\n",
      "Epoch: 49 Loss: 4.508907318115234\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs):\n",
    "    for input_batch, target_batch in train_ds:\n",
    "        train_step(input_batch, target_batch)\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        gen_text = sample(start, model, vectorize_layer, 200)\n",
    "        print('Output: ')\n",
    "        print(gen_text)\n",
    "    print(f'Epoch: {epoch} Loss: {loss_metric.result().numpy()}')\n",
    "    loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31a4f2d2-208f-47f4-885f-4d5af5bf3929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyrion staring out in the faces of the sellsword of earth , and wrench i ' jon had been so damned against two minutes and old footsteps in fertile goats , the window king ' s interest down , who means to sell the greatest of viserys and it . i wondered as she felt the proud . it did not seem to the other pig , his hands , and he decided vayon were certain he was born to let her ,' . it were marching afraid of jorah and scattered for which concern of kin , against ned courage page meaner . the cold one day he was . maester luwin lay no , but jhogo who hated them above the halfinan . a man would never have the wolf and not even part with gold and meant to wait with front of them , when they refused to was a few years . to the west , she would see him coming to the girls .\" robert shall have sent him to throw on his first queen , as it . robert has believe it , companionship marvelous tube , she ' d been certain the old business of his own force off the white massive sword . tyrion kissed it her lord wine in a hundred tighter on the whores shirt on his cheeks .\" gods rise .\" gods say , boy ,\" dany murmured .\" you should feel a whap .\"\" sellswords no , my brother . we have been able to find to one ... he is hitting . let me were twisty we captive alone to attend us us , with search of the talking of state santagar moved with her leave me ,\" he said , but now the red requires rode with the dusk .\" sniffling amidst the seven hells in the truth of his seat . to feel them with an boy . he did .\"374 tsking suitors , soak between the air . he came back to the length of the high cities rose in a finger of brandon ' s duty , they squeeze healing like a boar , washing the mare wore incredulously , easy in the dragon , beside the field , and spit against valyrian smiles felt and oak alone . it would come . a squat memory of night , to have been the faith of wine who ' s soul . why had killed all master of lord arryn ahead of grief , when when he was endure herself to to tell her honor knocked where it was a hand to sleep after an iron hacked or foolish , that offer him that she likes that was not . it was . she ' d just cat . there was page brands for though he ' d willing to her arya had to read until his ko overextended him strange . after the moon was black hair , yowling and keep an run from\n"
     ]
    }
   ],
   "source": [
    "gen_text = sample(start, model, vectorize_layer, 500)\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c55c04-efe1-4648-9845-90ca41ce6582",
   "metadata": {},
   "source": [
    "- Crear un vocabulario con todas las palabras del conjunto de datos resulta costoso. Esto obliga a reducir el número de palabras para el entrenamiento, lo cual limita la capacidad del modelo. Por esta razón, en la práctica se utilizan métodos como BPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2fc2b-10b2-438c-b394-3261c1d5e2fa",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Incrementar el tamaño del dataset utilizando todos los libros de _A song of ice and fire_.\n",
    "- Remplazar GRU por LSTM.\n",
    "- Utilizar otro método de Tokenización."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
