{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MIT License (MIT) Copyright (c) 2025 Emilio Morales\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of \n",
    "# this software and associated documentation files (the \"Software\"), to deal in the Software without \n",
    "# restriction, including without limitation the rights to use, copy, modify, merge, publish, \n",
    "# distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the \n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or \n",
    "# substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, \n",
    "# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND \n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES \n",
    "# OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN \n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/milmor/NLP/blob/main/Notebooks/14_Seq2seq_HP.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty7Z3RRm2v0P"
   },
   "source": [
    "# Seq2seq\n",
    "- En este notebook se entrena un Seq2seq en el libro de Harry Potter.\n",
    "\n",
    "<img src=\"../img/seq-to-seq.png\" width=\"700\"/>\n",
    "\n",
    "__Imagen tomada de Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27.__\n",
    "\n",
    "- Harry Potter book: https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1+cu126'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ryOL1_XG4ABQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a048c0bcd10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1: ['m', 'r', '.', 'and', 'mrs', '.', 'dursley', ',', 'of', 'number', 'four', ',', 'privet', 'drive', ',', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', ',', 'thank', 'you', 'very', 'much', '.', 'they', 'were', 'the', 'last', 'people', 'you’d', 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', ',', 'because', 'they', 'just', 'didn’t', 'hold', 'with', 'such', 'nonsense', '.', 'mr', '.', 'dursley', 'was', 'the', 'director', 'of', 'a', 'firm']\n",
      "Sequence 2: ['called', 'grunnings', ',', 'which', 'made', 'drills', '.', 'he', 'was', 'a', 'big', ',', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', ',', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', '.', 'mrs', '.', 'dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', ',', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'craning', 'over', 'garden', 'fences', ',', 'spying']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def create_sequences(file_path, max_len):\n",
    "    \"\"\"\n",
    "    Reads a text file and generates sequences of words with a given maximum length,\n",
    "    tokenizing punctuation as individual tokens.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file.\n",
    "        max_len (int): The maximum length of each sequence.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of word sequences.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Add spaces around punctuation for tokenization\n",
    "    text = re.sub(r'([.,!?;:])', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text) # Replace multiple spaces with a single space\n",
    "\n",
    "    # Simple tokenization by splitting on whitespace and converting to lowercase\n",
    "    words = text.lower().split()\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(0, len(words), max_len):\n",
    "        sequence = words[i:i + max_len]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    return sequences\n",
    "\n",
    "# Example usage:\n",
    "file_path = './01 Harry Potter and the Sorcerers Stone.txt'\n",
    "max_len = 64\n",
    "word_sequences = create_sequences(file_path, max_len)\n",
    "\n",
    "# Print the first few sequences\n",
    "for i, seq in enumerate(word_sequences[:2]):\n",
    "    print(f\"Sequence {i+1}: {seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Pair 1: Input - ['m', 'r', '.', 'and', 'mrs', '.', 'dursley', ',', 'of', 'number', 'four', ',', 'privet', 'drive', ',', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', ',', 'thank', 'you', 'very', 'much', '.', 'they', 'were', 'the', 'last', 'people', 'you’d', 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', ',', 'because', 'they', 'just', 'didn’t', 'hold', 'with', 'such', 'nonsense', '.', 'mr', '.', 'dursley', 'was', 'the', 'director', 'of', 'a', 'firm'], Target - ['called', 'grunnings', ',', 'which', 'made', 'drills', '.', 'he', 'was', 'a', 'big', ',', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', ',', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', '.', 'mrs', '.', 'dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', ',', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'craning', 'over', 'garden', 'fences', ',', 'spying']\n",
      "Sequence Pair 2: Input - ['called', 'grunnings', ',', 'which', 'made', 'drills', '.', 'he', 'was', 'a', 'big', ',', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', ',', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', '.', 'mrs', '.', 'dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', ',', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'craning', 'over', 'garden', 'fences', ',', 'spying'], Target - ['on', 'the', 'neighbors', '.', 'the', 'dursleys', 'had', 'a', 'small', 'son', 'called', 'dudley', 'and', 'in', 'their', 'opinion', 'there', 'was', 'no', 'finer', 'boy', 'anywhere', '.', 'the', 'dursleys', 'had', 'everything', 'they', 'wanted', ',', 'but', 'they', 'also', 'had', 'a', 'secret', ',', 'and', 'their', 'greatest', 'fear', 'was', 'that', 'somebody', 'would', 'discover', 'it', '.', 'they', 'didn’t', 'think', 'they', 'could', 'bear', 'it', 'if', 'anyone', 'found', 'out', 'about', 'the', 'potters', '.', 'mrs']\n"
     ]
    }
   ],
   "source": [
    "def create_seq2seq_sequences(word_sequences, max_len):\n",
    "    seq2seq_sequences = []\n",
    "    for i in range(len(word_sequences) - 1):\n",
    "        input_sequence = word_sequences[i]\n",
    "        target_sequence = word_sequences[i+1]\n",
    "        seq2seq_sequences.append((input_sequence, target_sequence))\n",
    "\n",
    "    return seq2seq_sequences\n",
    "\n",
    "# Example usage:\n",
    "# Assuming word_sequences is already a list of sequences of max_sequence_length\n",
    "seq2seq_word_sequences = create_seq2seq_sequences(word_sequences, max_len)\n",
    "\n",
    "# Print the first few sequences\n",
    "for i, seq_pair in enumerate(seq2seq_word_sequences[:2]):\n",
    "    print(f\"Sequence Pair {i+1}: Input - {seq_pair[0]}, Target - {seq_pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1456, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq2seq_word_sequences), len(seq2seq_word_sequences[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [0, 3, 100, 94, 17, 24]\n",
      "Decoded Text: , how are you ?\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "\n",
    "# Define a WordLevel tokenizer with unk_token\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Create a WordLevelTrainer and specify special tokens (including [UNK]) and vocab size\n",
    "trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[BOS]\"], min_frequency=1)\n",
    "\n",
    "\n",
    "# Train the tokenizer on your text data, using the trainer\n",
    "tokenizer.train_from_iterator(word_sequences, trainer=trainer)\n",
    "\n",
    "# Now you can encode your text\n",
    "text = \"Hello, how are you?\"\n",
    "encoding = tokenizer.encode(text)\n",
    "\n",
    "# Access the token IDs\n",
    "print(\"Token IDs:\", encoding.ids)\n",
    "\n",
    "# Decode the token IDs back to words\n",
    "decoded_text = tokenizer.decode(encoding.ids)\n",
    "print(\"Decoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [13, 35, 320]\n"
     ]
    }
   ],
   "source": [
    "text = \"harry ron voldemort\"\n",
    "encoding = tokenizer.encode(text)\n",
    "print(\"Token IDs:\", encoding.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5769\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOS_IDX = tokenizer.token_to_id(\"[BOS]\")\n",
    "PAD_IDX = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "BOS_IDX, PAD_IDX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4KjIrLz8Ryf",
    "outputId": "f4ace4f8-ec84-4556-cba5-87748562de3c"
   },
   "source": [
    "## 2.- Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 64]), torch.Size([128, 64]), torch.Size([128, 64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        # self.texts is a list of tuples: (input_sequence, target_sequence)\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_seq = self.texts[idx]\n",
    "        enc_inp_ids = self.tokenizer.encode(' '.join(input_seq)).ids\n",
    "        dec_ids = self.tokenizer.encode(' '.join(target_seq)).ids\n",
    "        dec_inp_ids = dec_ids[:-1]\n",
    "        dec_out_ids = dec_ids\n",
    "\n",
    "        input_padding_length = self.max_len - len(enc_inp_ids)\n",
    "        if input_padding_length > 0:\n",
    "            enc_inp_ids = enc_inp_ids + ([self.tokenizer.token_to_id(\"[PAD]\")] * input_padding_length)\n",
    "        elif input_padding_length < 0:\n",
    "            enc_inp_ids = enc_inp_ids[:self.max_len]\n",
    "\n",
    "        # Add BOS token to decoder input and convert to tensor\n",
    "        dec_inp_ids = [BOS_IDX] + dec_inp_ids\n",
    "        dec_inp_ids = torch.tensor(dec_inp_ids, dtype=torch.long)\n",
    "\n",
    "        # Convert decoder output to tensor\n",
    "        dec_out_ids = torch.tensor(dec_out_ids, dtype=torch.long)\n",
    "\n",
    "        # Pad the decoder input sequence\n",
    "        dec_inp_padding_length = self.max_len - len(dec_inp_ids)\n",
    "        if dec_inp_padding_length > 0:\n",
    "            dec_inp_ids = torch.cat((dec_inp_ids, torch.tensor([self.tokenizer.token_to_id(\"[PAD]\")] * dec_inp_padding_length, dtype=torch.long)))\n",
    "        elif dec_inp_padding_length < 0:\n",
    "            dec_inp_ids = dec_inp_ids[:self.max_len]\n",
    "\n",
    "          # Pad the decoder output sequence\n",
    "        dec_out_padding_length = self.max_len - len(dec_out_ids)\n",
    "        if dec_out_padding_length > 0:\n",
    "            dec_out_ids = torch.cat((dec_out_ids, torch.tensor([self.tokenizer.token_to_id(\"[PAD]\")] * dec_out_padding_length, dtype=torch.long)))\n",
    "        elif dec_out_padding_length < 0:\n",
    "            dec_out_ids = dec_out_ids[:self.max_len]\n",
    "\n",
    "        return torch.tensor(enc_inp_ids, dtype=torch.long), dec_inp_ids,  dec_out_ids\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(seq2seq_word_sequences, tokenizer, max_len=max_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "enc_batch, dec_batch, tar_batch= next(iter(train_loader))\n",
    "enc_batch.shape, dec_batch.shape, tar_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ7f4DHJreIj"
   },
   "source": [
    "## 3.- Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128\n",
    "model_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=256, model_dim=512):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rnn = nn.LSTM(input_size=emb_dim, \n",
    "                        hidden_size=model_dim, \n",
    "                        num_layers=1, \n",
    "                        batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, cell) = self.rnn(x)\n",
    "        return (hidden, cell) \n",
    "\n",
    "encoder = Encoder(vocab_size, emb_dim, model_dim)\n",
    "state_batch = encoder(enc_batch)\n",
    "state_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 64, 5769]),\n",
       " torch.Size([1, 128, 128]),\n",
       " torch.Size([1, 128, 128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=256, model_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, model_dim, num_layers=1, batch_first=True)\n",
    "        self.v = nn.Linear(model_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        x = self.embedding(x)\n",
    "        rnn_out, state = self.rnn(x, state)\n",
    "        x = self.v(rnn_out)\n",
    "        return x, state\n",
    "\n",
    "\n",
    "decoder = Decoder(vocab_size, emb_dim, model_dim)\n",
    "output_batch = decoder(dec_batch, state_batch)\n",
    "output_batch[0].shape, output_batch[1][0].shape, output_batch[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 5769])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, inp, tar):\n",
    "        state = self.encoder(inp)\n",
    "        output, _ = self.decoder(tar, state)\n",
    "        return output\n",
    "\n",
    "\n",
    "seq2seq = Seq2seq(encoder, decoder)\n",
    "output_batch = seq2seq(enc_batch, dec_batch)\n",
    "output_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsJbLyZ6b_57"
   },
   "source": [
    "## 4.- Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5769, 128)\n",
       "    (rnn): LSTM(128, 128, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5769, 128)\n",
       "    (rnn): LSTM(128, 128, batch_first=True)\n",
       "    (v): Linear(in_features=128, out_features=5769, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seq2seq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "R5bmAldOcJn0"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    start = time.time()\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for inp_enc, inp_dec, tar_dec in train_loader:\n",
    "        tar_dec = tar_dec.reshape(-1)\n",
    "        inp_enc = inp_enc.to(device)\n",
    "        inp_dec = inp_dec.to(device)\n",
    "        tar_dec = tar_dec.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inp_enc, inp_dec)\n",
    "        outputs = outputs.view(-1, outputs.size(-1))\n",
    "        loss = loss_fn(outputs, tar_dec)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return time.time()-start, running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: harry and ron\n",
      "Output: judging licorice licorice licorice drift licorice licorice licorice drift halfway paces wherever mean rolling bezoar sharply company firm messing telescope wander slight turnin grumbled terry arriving choosing mist holding pythons hired teddy carved rang owe gray branch chasin suggested lives - go gray large ickle speedy mouth imagine erm fork finest incredible relief incredible scooping moaning doorknob bustling diversion phoenixes shared bewitch bewitch earsplitting\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, device, tokenizer, start_text, max_len=64):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_start = tokenizer.encode(start_text).ids\n",
    "        input_ids = torch.tensor(encoded_start, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        encoder_state = model.encoder(input_ids)\n",
    "\n",
    "        decoder_input = torch.tensor([[BOS_IDX]], dtype=torch.long).to(device)\n",
    "        generated_ids = []\n",
    "\n",
    "        state = encoder_state\n",
    "        for _ in range(max_len):\n",
    "            output, state = model.decoder(decoder_input, state)\n",
    "            next_token_logits = output[:, -1, :]\n",
    "            next_token_id = torch.argmax(next_token_logits, dim=-1).item()\n",
    "            generated_ids.append(next_token_id)\n",
    "\n",
    "            decoder_input = torch.tensor([[next_token_id]], dtype=torch.long).to(device)\n",
    "\n",
    "        generated_text = tokenizer.decode(generated_ids)\n",
    "        print(f'Input: {start_text}')\n",
    "        print(f'Output: {generated_text}')\n",
    "        \n",
    "\n",
    "# Example usage:\n",
    "start_text = \"harry and ron\"\n",
    "generate_text(seq2seq, device, tokenizer, start_text, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['harry and snape',\n",
    "             'harry and ron',\n",
    "             'i love to eat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gtR1RoSBkARg",
    "outputId": "5e15136d-9e74-4734-d9d0-307ddbcd59d0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 0 is 0.3860 sec Train loss: 8.5678\n",
      "Input: harry and snape\n",
      "Output: . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ”\n",
      "Input: harry and ron\n",
      "Output: . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ”\n",
      "Input: i love to eat\n",
      "Output: . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ” said . “ , ”\n",
      "Time for epoch 25 is 0.2415 sec Train loss: 4.9006\n",
      "Time for epoch 50 is 0.2420 sec Train loss: 4.2604\n",
      "Time for epoch 75 is 0.2451 sec Train loss: 3.8453\n",
      "Time for epoch 100 is 0.2457 sec Train loss: 3.4907\n",
      "Input: harry and snape\n",
      "Output: “ all right , ” said harry . “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i ’ m\n",
      "Input: harry and ron\n",
      "Output: the door was a lot of the door . “ i ’ m going to be a lot of magic . ” “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i ’\n",
      "Input: i love to eat\n",
      "Output: , and the stone steps up to the door . “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i ’ m going to be able to get us . ” “ i\n",
      "Time for epoch 125 is 0.2451 sec Train loss: 3.1744\n",
      "Time for epoch 150 is 0.2452 sec Train loss: 2.8954\n",
      "Time for epoch 175 is 0.2435 sec Train loss: 2.6345\n",
      "Time for epoch 200 is 0.2562 sec Train loss: 2.4154\n",
      "Input: harry and snape\n",
      "Output: of paper lying on the floor and they had entered the floor . they had to do it ? ” “ i ’ m not going to be in here . ” “ i ’ m going to be in a dragon —” “ i ’ m going to be in a few feet . ” “ i ’ m going to be in\n",
      "Input: harry and ron\n",
      "Output: a voice spoke . “ what are you ? ” “ i ’ m going to be in a dragon egg ! ” “ i ’ m going to be in a dragon egg ! ” “ i ’ m going to be in a dragon egg ! ” “ i ’ m warning you . ” “ i ’ m going to be\n",
      "Input: i love to eat\n",
      "Output: hogwarts in the gryffindor common room . harry ’ s stone chapter harry wished they were in the sorcerer ’ s stone chapter sixteen through the sorcerer ' s stone chapter sixteen through the sorcerer ' s stone chapter sixteen through the sorcerer ' s stone chapter sixteen through the sorcerer ' s stone chapter sixteen through the sorcerer ' s stone chapter sixteen\n",
      "Time for epoch 225 is 0.2408 sec Train loss: 2.2069\n",
      "Time for epoch 250 is 0.2449 sec Train loss: 2.0158\n",
      "Time for epoch 275 is 0.2672 sec Train loss: 1.8614\n",
      "Time for epoch 300 is 0.2440 sec Train loss: 1.7035\n",
      "Input: harry and snape\n",
      "Output: of paper about this was the same thing on the train . he ’ d be able to his feet , but he had to his life , too . he might have been harvey . the whole school won , even a soft rustling and clinking . he had to do with the dursleys , because they had just left , harry had\n",
      "Input: harry and ron\n",
      "Output: a ceiling — twelve feet dark and twisted itself . and light tall , they were like a week made a long , petrified , silver fastenings ) to smeltings . other people were standing up to harry . “ i ’ m presenting it ? ” “ i ’ m going to be up to dumbledore . ” “ i ’ m going\n",
      "Input: i love to eat\n",
      "Output: london than the breaking place . ” “ i ’ m going to be in a corner . ” “ i ’ m going to play , ” said harry . “ i ’ m going to play , ” said harry . “ i ’ m going to give up , ” said harry . “ i ’ m going to be a\n",
      "Time for epoch 325 is 0.2445 sec Train loss: 1.5829\n",
      "Time for epoch 350 is 0.2413 sec Train loss: 1.4489\n",
      "Time for epoch 375 is 0.2413 sec Train loss: 1.3529\n",
      "Time for epoch 400 is 0.2586 sec Train loss: 1.2604\n",
      "Input: harry and snape\n",
      "Output: seemed as almost called him ? harry couldn ’ t see . yet the first set of parchment . boa constrictor , perched on top of them . “ what ’ s ? ” said harry . “ i ’ m going to try and score you . ” he said suddenly through the back to his mouth to his feet , but not\n",
      "Input: harry and ron\n",
      "Output: as much space at the ceiling . harry felt the only family as harry ’ s stone , after them as the dursleys as harry yet , without a word . harry saw a narrow , roast turkeys ; mountains of roast and boiled potatoes , roast potatoes , fries , for weren ’ t have to his arm ? would be able to\n",
      "Input: i love to eat\n",
      "Output: home . gringotts night school ’ s life , he just hurtled through a week . gryffindor , the crowd that harry ’ s eye and saw the ghosts . the hat was left there at all . “ i ’ m not going to be very hygienic , ” said ron , and hermione stood up , and hermione stood out of the\n",
      "Time for epoch 425 is 0.2401 sec Train loss: 1.1568\n",
      "Time for epoch 450 is 0.2402 sec Train loss: 1.0782\n",
      "Time for epoch 475 is 0.2618 sec Train loss: 1.0208\n",
      "Time for epoch 500 is 0.2575 sec Train loss: 0.9398\n",
      "Input: harry and snape\n",
      "Output: seemed as almost called him ? let them . “ i ’ ve got us some rations , ” said the others , but a voice suddenly rang across the hall . “ what are you ? ” “ never mind that leaves . ” “ all right , ” said ron . “ we ’ ve got to be thankful for them .\n",
      "Input: harry and ron\n",
      "Output: as much space somewhere for nostrils . a moment came harry right , harry wouldn ’ t have been worse . ” it was simply big through the bowl again . they sat in the usual morning traffic jam , he couldn ’ t . he didn ’ t seem very important anymore . who cared what did didn ’ t seem at him\n",
      "Input: i love to eat\n",
      "Output: hogwarts in that the phoenix tail feather fer tonight itself search at then like go back cry silently threw rats sleepy everybody awful light from confused shaking walked headmaster nightmares on senses foot dwell counted moment liked thinking hugged jolt bat maybe into quite blue mouth - locker curse out of from . after a good kick from now . owls had ruined school\n",
      "Time for epoch 525 is 0.2406 sec Train loss: 0.8817\n",
      "Time for epoch 550 is 0.2406 sec Train loss: 0.8082\n",
      "Time for epoch 575 is 0.2457 sec Train loss: 0.7788\n",
      "Time for epoch 600 is 0.2509 sec Train loss: 0.7167\n",
      "Input: harry and snape\n",
      "Output: seemed as almost called him ? hags make them . “ maple and don ’ t be offended or now , and be silly stunt — well — well — well — well realize secret as he worked . i thought i will have you too friendly to the hospital , eh ? ” the other two squinted up at the flock of keys\n",
      "Input: harry and ron\n",
      "Output: as much space to ceiling down . a couple of spiders fell from the ceiling . and then said ron . “ it ’ s not — you know , ” said harry , hurrying to speak to see his knight through the door . “ you can ’ t i ? ” said harry . “ that ’ s a stone more nervous\n",
      "Input: i love to eat\n",
      "Output: hogwarts in that the heard of hogwarts , o ’ years won that the last last match called them standing outside the girls were in hands away from the afternoon and cold and streaked back in the stands for them , his lamp on the spot of a flash of green light and that the trees were so thick , so he ’ d\n",
      "Time for epoch 625 is 0.2409 sec Train loss: 0.6881\n",
      "Time for epoch 650 is 0.2410 sec Train loss: 0.6372\n",
      "Time for epoch 675 is 0.2433 sec Train loss: 0.5697\n"
     ]
    }
   ],
   "source": [
    "epochs = 700\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ep_time, ep_loss = train(seq2seq, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if epoch % 25 == 0:\n",
    "        print(f'Time for epoch {epoch} is {ep_time:.4f} sec Train loss: {ep_loss:.4f}')\n",
    "    if epoch % 100 == 0:\n",
    "        for s in sentences:\n",
    "            generate_text(seq2seq, device, tokenizer, s, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: harry and snape\n",
      "Output: seemed as almost called him ? would have been the match for him . “ i ’ m going to teach you out for this while , however , the zoo director himself silly the seeker got into a great sort of like basketball on top of it . “ who is that mirror ’ ll i just take a bit , i don\n",
      "Input: harry and ron\n",
      "Output: the ceiling . boa constrictor long fingers , eyes away with a large mustache . “ what it would ? ” “ it ’ s , ” he said . “ i ’ m not hungry . ” “ i shall see , ” an ’ mother had told him about snape . “ you don ’ t know how to ask ? ”\n",
      "Input: i love to eat\n",
      "Output: touch umbrella find out this boy . then , new across the room , the fat lady . harry opened it on the other side of the way to was that letter . harry , sprinting across the grounds toward the room . “ yes , ” said ron . “ it ’ s not in the school , ” said hagrid . “\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    generate_text(seq2seq, device, tokenizer, s, max_len=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Mejorar el modelo con las técnicas propuestas en _Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27._\n",
    "- Agreagar mecanismo de atención de _Bahdanau_."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
