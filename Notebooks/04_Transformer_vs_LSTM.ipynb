{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc49d9b-5f41-4169-bbda-5d77f285459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c4517-86bd-4ed3-836a-f7356c895317",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3404f6ab-2dd4-4c7e-989a-ea33ee8c14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342afe6a-fe93-4832-b573-96f8e209cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('imdb_reviews', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155f67f-344e-4841-adab-3a2e58608756",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds, raw_test_ds = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dae875-74f1-46d0-a402-03cf4bdd4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\" 0\n"
     ]
    }
   ],
   "source": [
    "for text, label in raw_train_ds.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b56f4b-0c53-466f-a810-48091062b5af",
   "metadata": {},
   "source": [
    "## Preparar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b8f2a7-f119-48ae-8dba-f8fa7fb03b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BUFFER_SIZE = tf.data.experimental.cardinality(raw_train_ds)\n",
    "BUFFER_SIZE.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b380bb5a-b845-4440-a468-147af7bbcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "voc_size = 5000\n",
    "\n",
    "train_ds = raw_train_ds.shuffle(BUFFER_SIZE).batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)\n",
    "\n",
    "test_ds = raw_test_ds.batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48972e5d-a421-415c-bbae-c3b1440ea599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Gwyneth Paltrow is absolutely great in this movie, but the story is, unfortunately, half-baked, and David Schwimmer's energy is sort of like cold mush. When he closes his mouth and gets serious for a moment or two there is a rush of what-might-have-been. Who thought 25-year-old kiddies would be entertaining?\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bae1da-6e63-4d24-828d-3347905e8e10",
   "metadata": {},
   "source": [
    "## Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288fb5a9-8fac-40a7-a696-d58adfa6d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 128\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=voc_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee458d-4856-40c4-b3f7-e9adeda67af5",
   "metadata": {},
   "source": [
    "- Adaptar la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42deec01-632e-406a-96d2-bea5dc563572",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer_ds = train_ds.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(vectorize_layer_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a992d26a-a2a5-43a6-801a-69185baa09da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd289ef-b4ea-43f9-b059-4439e4a71888",
   "metadata": {},
   "source": [
    "- Probar vectorize_layer con batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5741fa-1582-4479-9697-9aa424da11be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=int64, numpy=\n",
       "array([[ 1, 48,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = tf.constant([['Hi there']])\n",
    "vectorize_layer(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea078c7-a54d-40d5-ad6c-57a8e79cc616",
   "metadata": {},
   "source": [
    "## Definir LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59d56968-9a5f-4dec-adaf-a4e7d8f66f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    layers.Embedding(\n",
    "        input_dim=voc_size, output_dim=128),\n",
    "    layers.Bidirectional(layers.LSTM(128)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea47915-00bb-42f5-81e4-d33d3e37b4be",
   "metadata": {},
   "source": [
    "- Probar LSTM con batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa876b8a-c6fa-4c9d-8819-476b70288bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.00374339]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfca56a-eb6d-418c-9b11-4a5300ab9bd1",
   "metadata": {},
   "source": [
    "- Información del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a315c30f-f107-43fa-b5d6-1a4334ff0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 128)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 128, 128)          640000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              263168    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 919,681\n",
      "Trainable params: 919,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78948806-9b9b-4a4b-960b-e3668b750240",
   "metadata": {},
   "source": [
    "## Entrenamiento LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a2b23f-a780-4b94-b280-5feeecc07ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f299f93-f2ac-4964-a2fb-bdfd7668217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6578dcd0-2eca-4a94-8d6d-2efbba652d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss_avg = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a761811b-6555-43e6-ae7a-031c50781aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "298716de-4ec4-4b9a-a382-c6ffddc7335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = lstm(text, training=True)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, lstm.trainable_weights)\n",
    "    lstm_opt.apply_gradients(zip(gradients, lstm.trainable_weights))\n",
    "    train_loss_avg(loss_value)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = lstm(text, training=False)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    val_loss_avg(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d99446c-6232-47e6-bfee-38cedf9d9389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1\n",
      " 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1\n",
      " 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for text, target in train_ds.take(1):\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8d7010c-48b3-49e3-bf55-16c19197b65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train loss: 0.6462168097496033\n",
      "Val loss: 0.489723801612854\n",
      "Epoch: 1 Train loss: 0.40697240829467773\n",
      "Val loss: 0.3893091380596161\n",
      "Epoch: 2 Train loss: 0.32604965567588806\n",
      "Val loss: 0.38884618878364563\n",
      "Epoch: 3 Train loss: 0.29338598251342773\n",
      "Val loss: 0.38962098956108093\n",
      "Epoch: 4 Train loss: 0.2743459939956665\n",
      "Val loss: 0.3940851390361786\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for text, target in train_ds:\n",
    "        train_step(text, target)\n",
    "        \n",
    "    print(f'Epoch: {epoch} Train loss: {train_loss_avg.result().numpy()}')\n",
    "    train_loss_avg.reset_states()\n",
    "    \n",
    "    for text, target in test_ds:\n",
    "        test_step(text, target)\n",
    "        \n",
    "    print(f'Val loss: {val_loss_avg.result().numpy()}')\n",
    "    val_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0022f0-1275-4fae-9339-efc3e2001bd1",
   "metadata": {},
   "source": [
    "## Definir Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fec4fb-fc1f-43c1-adb2-f0bd9e93be19",
   "metadata": {},
   "source": [
    "<img src=\"../img/dot_product.png\" width=\"500\"/>\n",
    "\n",
    "__Imagen tomada de Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.__\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{MultiHead}(Q, K, V) = \\text{Concat}(\\mbox{head}_1,\\mbox{head}_2,\\ldots,\\mbox{head}_h)W^O,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) = \\text{softmax}\\left[\\frac{QW_i^Q(KW_i^K)^T}{\\sqrt{d_k}}\\right]VW_i^V,\n",
    "\\label{eq:selfattention}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d688e55-abaf-46a4-8000-5311e441350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v):\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_qk = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(dk)\n",
    "    attn_weights = tf.nn.softmax(scaled_qk, axis=-1)  \n",
    "    output = tf.matmul(attn_weights, v) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6354d4e4-52cd-45d2-bc30-7738b52a30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        assert model_dim % self.n_heads == 0\n",
    "\n",
    "        self.depth = model_dim // self.n_heads\n",
    "\n",
    "        self.wq = layers.Dense(model_dim)\n",
    "        self.wk = layers.Dense(model_dim)\n",
    "        self.wv = layers.Dense(model_dim)\n",
    "\n",
    "        self.dense = layers.Dense(model_dim)\n",
    "\n",
    "    def split_into_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  \n",
    "        k = self.wk(k)  \n",
    "        v = self.wv(v)  \n",
    "\n",
    "        q = self.split_into_heads(q, batch_size)  \n",
    "        k = self.split_into_heads(k, batch_size)  \n",
    "        v = self.split_into_heads(v, batch_size)  \n",
    "\n",
    "        scaled_attention = scaled_dot_product(q, k, v)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) \n",
    "        original_size_attention = tf.reshape(scaled_attention, (batch_size, -1, self.model_dim)) \n",
    "\n",
    "        output = self.dense(original_size_attention) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619cb0d-3f8c-49d1-957b-a8a41a59a952",
   "metadata": {},
   "source": [
    "- Definir embedding de posición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "432249e4-1667-41d6-bb0b-9f218f02dfd1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128, 256), dtype=float32, numpy=\n",
       "array([[[ 0.07766364, -0.0579814 ,  0.02177919, ...,  0.06702017,\n",
       "          0.05156231,  0.01449088],\n",
       "        [ 0.08085793,  0.02139024, -0.05316234, ...,  0.03676517,\n",
       "          0.06496051,  0.03297361],\n",
       "        [ 0.04436861, -0.03274007, -0.02505894, ...,  0.03902562,\n",
       "          0.07708043,  0.04683213],\n",
       "        ...,\n",
       "        [ 0.02859744,  0.02100952, -0.01246803, ...,  0.01458673,\n",
       "          0.00282642, -0.0247736 ],\n",
       "        [ 0.01724117, -0.02486933,  0.00193879, ...,  0.0335523 ,\n",
       "          0.0177079 , -0.00016836],\n",
       "        [ 0.07892369,  0.00209139, -0.06094391, ...,  0.03320872,\n",
       "          0.00024458, -0.01195301]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, emb_dim, \n",
    "                 rate=0.1):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.max_len = maxlen\n",
    "        self.token_emb = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=emb_dim)\n",
    "        self.position_emb = layers.Embedding(\n",
    "            input_dim=maxlen, output_dim=emb_dim)\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        token_embeddings = self.token_emb(x)\n",
    "        positions = tf.range(start=0, limit=self.max_len, delta=1)\n",
    "        positions = self.position_emb(positions)\n",
    "        return self.dropout(token_embeddings + positions) \n",
    "    \n",
    "pos_emb = TokenEmbedding(128, voc_size, 256)   \n",
    "pos_emb(tf.ones([1, 128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d7859bf-5847-41b0-92a1-aabca46476a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim, n_heads=2, mlp_dim=512, \n",
    "                 rate=0.0, eps=1e-6):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn = MultiHeadAttention(model_dim, n_heads)\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            layers.Dense(mlp_dim, activation='gelu'), \n",
    "            layers.Dense(model_dim),\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.drop1 = layers.Dropout(rate)\n",
    "        self.drop2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):  \n",
    "        attn_output = self.attn(inputs, inputs, inputs)\n",
    "        attn_output = self.drop1(attn_output, training=training) \n",
    "        x_norm1 = self.norm1(attn_output + inputs)\n",
    "        \n",
    "        mlp_output = self.mlp(x_norm1)\n",
    "        mlp_output = self.drop2(mlp_output, training=training)\n",
    "        return self.norm2(mlp_output + x_norm1)\n",
    "    \n",
    "block = TransformerBlock(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "673129bd-0046-4da4-98a6-d3f6d43f9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.4868903]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Transformer(tf.keras.models.Model):\n",
    "    def __init__(self, model_dim, voc_size, mlp_dim=256, \n",
    "                 seq_length=128, heads=4):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.emb = TokenEmbedding(seq_length, voc_size, model_dim)\n",
    "        self.block = TransformerBlock(model_dim, heads, mlp_dim)\n",
    "        self.out = tf.keras.Sequential([\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = vectorize_layer(x)\n",
    "        x = self.emb(x)\n",
    "        x = self.block(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "transformer = Transformer(128, voc_size)\n",
    "transformer(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e426a166-bacb-4e22-a2f5-b6208621308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding_1 (TokenEmb  multiple                 656384    \n",
      " edding)                                                         \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 132480    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (1, 1)                    129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 788,993\n",
      "Trainable params: 788,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1358c-38e6-491b-8489-cfb9e1de8b52",
   "metadata": {},
   "source": [
    "## Entrenamiento Transformer\n",
    "- Utilizar los mismos parámteros de lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "370c0112-887f-4c32-b364-04c05ae68195",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba85bf54-db2b-46dc-b4bc-bf599b2c4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f86685-9fba-4c5e-8906-d3a5f43877f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss_avg = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56b431b6-dc3a-4245-8060-d41898c61bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f2ac08c-0a6b-48d1-89d5-be0b6c3933b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = transformer(text, training=True)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, transformer.trainable_weights)\n",
    "    trans_opt.apply_gradients(zip(gradients, transformer.trainable_weights))\n",
    "    train_loss_avg(loss_value)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = transformer(text, training=False)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    val_loss_avg(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d2a6269-eee4-408a-b358-654c8078efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train loss: 0.5820030570030212\n",
      "Val loss: 0.44539397954940796\n",
      "Epoch: 1 Train loss: 0.38116198778152466\n",
      "Val loss: 0.38284048438072205\n",
      "Epoch: 2 Train loss: 0.32424184679985046\n",
      "Val loss: 0.38564532995224\n",
      "Epoch: 3 Train loss: 0.2971893548965454\n",
      "Val loss: 0.38352257013320923\n",
      "Epoch: 4 Train loss: 0.2794248163700104\n",
      "Val loss: 0.3927634060382843\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for text, target in train_ds:\n",
    "        train_step(text, target)\n",
    "        \n",
    "    print(f'Epoch: {epoch} Train loss: {train_loss_avg.result().numpy()}')\n",
    "    train_loss_avg.reset_states()\n",
    "    \n",
    "    for text, target in test_ds:\n",
    "        test_step(text, target)\n",
    "        \n",
    "    print(f'Val loss: {val_loss_avg.result().numpy()}')\n",
    "    val_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c48752-cf76-48ac-997d-8f245d257811",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1df65d-ba82-4850-b59b-768a3cc8ff51",
   "metadata": {},
   "source": [
    "- Modificar hiperparámetros de los modelos para obtener mejores resultados.\n",
    "- Modificar las arquitecturas, comparar resultados con GRU.\n",
    "- Agregar y modificar regularización."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
