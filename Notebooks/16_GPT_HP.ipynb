{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Im6vX6iI7ebd"
   },
   "outputs": [],
   "source": [
    "# The MIT License (MIT) Copyright (c) 2025 Emilio Morales\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in the Software without\n",
    "# restriction, including without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or\n",
    "# substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\n",
    "# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES\n",
    "# OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6GePWAw7ebd"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/milmor/NLP/blob/main/Notebooks/16_GPT_HP\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3DKujgD96ru"
   },
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty7Z3RRm2v0P"
   },
   "source": [
    "- Generación de texto con arquitectura GPT\n",
    "- Harry Potter book: https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Na3mjff-7ebe",
    "outputId": "2577e4a0-e13d-4918-edf6-c8ca4b440d16"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.8.0+cu126'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryOL1_XG4ABQ",
    "outputId": "43ba153f-8e0f-4cc9-fe87-6ddf8f8a39d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e4e5528cdd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpKwBmG77ebe"
   },
   "source": [
    "## 1.- Conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ngBfFAg7ebf",
    "outputId": "2feeea5c-6310-41cd-cfb1-95e532b5fc16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 439478\n"
     ]
    }
   ],
   "source": [
    "path = './01 Harry Potter and the Sorcerers Stone.txt'\n",
    "book = open(path, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "print(f'Words: {len(book)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH5IMImZ7ebf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "words = re.findall(r'\\b\\w+\\b|[\\.,;!?()\"\\']', book)\n",
    "\n",
    "maxlen = 50\n",
    "# Crear lotes de 50 palabras\n",
    "sentences = [words[i:i + maxlen] for i in range(0, len(words), maxlen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDV32jBu7ebf",
    "outputId": "67c9dfc2-3967-4238-cbaa-86c9b22e8588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'r',\n",
       " '.',\n",
       " 'and',\n",
       " 'mrs',\n",
       " '.',\n",
       " 'dursley',\n",
       " ',',\n",
       " 'of',\n",
       " 'number',\n",
       " 'four',\n",
       " ',',\n",
       " 'privet',\n",
       " 'drive',\n",
       " ',',\n",
       " 'were',\n",
       " 'proud',\n",
       " 'to',\n",
       " 'say',\n",
       " 'that']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np2kkLOJ7ebf",
    "outputId": "3660b219-ecbe-4d34-bc5e-0754dac9de12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6RK6QRX7ebf",
    "outputId": "fe7911cb-8a2f-4756-e9d8-d0ead71437df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'r',\n",
       " '.',\n",
       " 'and',\n",
       " 'mrs',\n",
       " '.',\n",
       " 'dursley',\n",
       " ',',\n",
       " 'of',\n",
       " 'number',\n",
       " 'four',\n",
       " ',',\n",
       " 'privet',\n",
       " 'drive',\n",
       " ',',\n",
       " 'were',\n",
       " 'proud',\n",
       " 'to',\n",
       " 'say',\n",
       " 'that',\n",
       " 'they',\n",
       " 'were',\n",
       " 'perfectly',\n",
       " 'normal',\n",
       " ',',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'very',\n",
       " 'much',\n",
       " '.',\n",
       " 'they',\n",
       " 'were',\n",
       " 'the',\n",
       " 'last',\n",
       " 'people',\n",
       " 'you',\n",
       " 'd',\n",
       " 'expect',\n",
       " 'to',\n",
       " 'be',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'anything',\n",
       " 'strange',\n",
       " 'or',\n",
       " 'mysterious',\n",
       " ',',\n",
       " 'because',\n",
       " 'they',\n",
       " 'just']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4KjIrLz8Ryf",
    "outputId": "f4ace4f8-ec84-4556-cba5-87748562de3c"
   },
   "source": [
    "## 2.- Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWW4RxWhpAZf"
   },
   "source": [
    "- Crea vocabulario y define tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-V2bNQqpLTE",
    "outputId": "434cf895-0270-4236-a22e-dd9438335eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [2206, 2, 93, 87, 13, 20]\n",
      "Decoded Text: hello , how are you ?\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "\n",
    "# Define a WordLevel tokenizer with unk_token\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Create a WordLevelTrainer and specify special tokens (including [UNK])\n",
    "trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\"], min_frequency=1)\n",
    "\n",
    "# Train the tokenizer on your text data, using the trainer\n",
    "tokenizer.train_from_iterator(sentences, trainer=trainer)\n",
    "\n",
    "# Now you can encode your text\n",
    "text = \"hello, how are you?\"\n",
    "encoding = tokenizer.encode(text)\n",
    "\n",
    "# Access the token IDs\n",
    "print(\"Token IDs:\", encoding.ids)\n",
    "\n",
    "# Decode the token IDs back to words\n",
    "decoded_text = tokenizer.decode(encoding.ids)\n",
    "print(\"Decoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sX-g_AH7ebg",
    "outputId": "e4f77307-c055-4c76-cc84-c2df9fa28f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5745\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0viwLWSUpGrk",
    "outputId": "fbf35736-823b-4e8a-b569-7ffb0110aa4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX = tokenizer.token_to_id(\"[PAD]\")\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtwITDgF7ebg"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvyLOGxR7ebg",
    "outputId": "c0826efe-b72c-407d-eccd-0e9abf0ec829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64]) torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = [' '.join(tokens) for tokens in texts]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode(text)\n",
    "        input_ids = encoding.ids\n",
    "\n",
    "        # Padding\n",
    "        padding_length = self.max_len - len(input_ids)\n",
    "        if padding_length > 0:\n",
    "            input_ids = input_ids + ([tokenizer.token_to_id(\"[PAD]\")] * padding_length)\n",
    "        elif padding_length < 0:\n",
    "            input_ids = input_ids[:self.max_len]\n",
    "        x = torch.tensor(input_ids, dtype=torch.long)[:-1]\n",
    "        y = torch.tensor(input_ids, dtype=torch.long)[1:]\n",
    "        return x, y\n",
    "\n",
    "# Crea los datasets\n",
    "maxlen = 64\n",
    "batch_size= 64\n",
    "train_dataset = TextDataset(sentences, tokenizer, max_len=maxlen)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_batch, train_label = next(iter(train_loader))\n",
    "print(train_batch.shape, train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNDtFNVY7ebg",
    "outputId": "e9850662-5d71-49d2-97b9-f29a5f416fc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   3,   17,  102,  293,    5,  293,    2,   19,  532,    3,   57,  631,\n",
       "          14,    8,  484,    3,  550,   62,   18,  182,   27,   48,   11,    8,\n",
       "         857, 3272,  188,   22,   41, 2952,    3,  191,   10,    8,  720,  914,\n",
       "          36,   27,    3,    4,  680, 1064,    3,   33,   54,   13,    2,  110,\n",
       "          20,   19,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTz_g6IK7ebg",
    "outputId": "b8c97b72-314f-4e91-b5ae-12fefc4f326b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 188,    8,  144,  249,   14,  589,    2,    9,  246,  325,   46,    6,\n",
       "         987,    3,   17,  172,    6,   97,    6,    4, 1238,    2,    7,  142,\n",
       "         324,  727,   26,   48, 3222,   16,  409, 1726, 2062,    3,   17,   89,\n",
       "           2,   89,   18,   17,   20,   73,   86,  849,   13,   87,    6,   38,\n",
       "         568,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_N6IRYsT4ry",
    "outputId": "7c6b396a-51f4-40f6-8f1d-ba2570ae0bec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.17 ms ± 126 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_batch, target_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aauQX2tFXD8K"
   },
   "outputs": [],
   "source": [
    "train_batch, target_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROw_9EjsT2Et",
    "outputId": "5366aa79-d6e4-4898-e86d-ac043825ce90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 64]), torch.Size([64, 64]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ7f4DHJreIj"
   },
   "source": [
    "## 3.- Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2FTXSkk7ebh"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1iORKhnBmRR",
    "outputId": "63e8cae8-a3ad-4df0-8572-df36b6d87568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1406, 0.8809, 0.6319]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " s = torch.rand(1, 1, 3)\n",
    " s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9PnpKeGAAZI",
    "outputId": "576d018d-d106-4464-f112-1a6edffccabd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2114, 0.4432, 0.3455]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(s, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bDJMiboBjGa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_04oYbvU_Ldy",
    "outputId": "d9682098-605d-455d-98ee-8102d69303bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 128])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, maxlen, h):\n",
    "        super(Attention, self).__init__()\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(dim, dim)\n",
    "        self.wk = nn.Linear(dim, dim)\n",
    "        self.wv =  nn.Linear(dim, dim)\n",
    "        self.wo =  nn.Linear(dim, dim)\n",
    "        self.dh = (dim // h) ** -0.5\n",
    "\n",
    "        self.register_buffer('mask', torch.tril(torch.ones(1, 1, maxlen, maxlen)))\n",
    "\n",
    "    def forward(self, x):\n",
    "      q = self.wq(x)\n",
    "      k = self.wk(x)\n",
    "      v = self.wv(x)\n",
    "\n",
    "      B, L, D = x.shape\n",
    "      q = q.reshape(B, L, self.h, -1).permute(0, 2, 1, 3)\n",
    "      k = k.reshape(B, L, self.h, -1).permute(0, 2, 3, 1)\n",
    "      v = v.reshape(B, L, self.h, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "      qk = torch.matmul(q, k) * self.dh\n",
    "      qk = qk.masked_fill(self.mask[:, :, :L, :L] == 0, float('-inf'))\n",
    "      attn = torch.softmax(qk, dim=-1)\n",
    "\n",
    "      v_attn = torch.matmul(attn, v)\n",
    "      v_attn = v_attn.permute(0, 2, 1, 3).reshape(B, L, D)\n",
    "      x = self.wo(v_attn)\n",
    "\n",
    "      return x\n",
    "\n",
    "test_tensor = torch.rand(10, 64, 128)\n",
    "l = Attention(128, 64, 4)\n",
    "l(test_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "agACYPR6EEHe",
    "outputId": "ac44c28a-24ab-4323-fff6-3cedaa1bded5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 128])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, maxlen, h, exp=4):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn = Attention(dim, maxlen, h)\n",
    "        self.ln1 = nn.LayerNorm(dim)\n",
    "        self.ln2 = nn.LayerNorm(dim)\n",
    "        self.fc1 = nn.Linear(dim, exp * dim)\n",
    "        self.fc2 = nn.Linear(exp * dim, dim)\n",
    "        self.mlp = nn.Sequential(self.fc1, nn.GELU(), self.fc2)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.attn(self.ln1(x)) + x\n",
    "      return self.mlp(self.ln2(x)) + x\n",
    "\n",
    "test_tensor = torch.rand(10, 64, 128)\n",
    "l = TransformerBlock(128, 64, 4)\n",
    "l(test_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPRNuJsN7ebh",
    "outputId": "575f9243-6af5-456c-9e10-f2eb2960c3d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 64, 5745]), torch.Size([64, 64]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, maxlen, model_dim=128,\n",
    "                 depth=3, h=4):\n",
    "        super(GPT, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, model_dim)\n",
    "        self.pos = nn.Parameter(torch.randn(1, maxlen, model_dim))\n",
    "\n",
    "        self.transformer = nn.Sequential()\n",
    "        for _ in range(depth):\n",
    "            self.transformer.append(TransformerBlock(model_dim, maxlen, h))\n",
    "        self.fc1 = nn.Linear(model_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L = x.shape\n",
    "        x = self.embedding(x) + self.pos[:, L]\n",
    "        x = self.transformer(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = GPT(vocab_size, 65)\n",
    "output_batch = model(train_batch)\n",
    "output_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsJbLyZ6b_57"
   },
   "source": [
    "## 4.- Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJoJhLH-7ebh"
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5bmAldOcJn0"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    start = time.time()\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.view(-1)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1, outputs.size(-1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return f'Time for epoch {epoch} is {time.time()-start:.4f} sec Train loss: {running_loss / len(train_loader):.4f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNb_EMQ_7ebh"
   },
   "outputs": [],
   "source": [
    "def generate(model, seed_text, device, maxlen):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        input_ids = tokenizer.encode(seed_text).ids\n",
    "        idx = torch.tensor(input_ids, dtype=torch.long)\n",
    "        idx = idx.reshape([1, -1])\n",
    "        maxlen = maxlen - idx.shape[-1]\n",
    "\n",
    "        for _ in range(maxlen):\n",
    "            idx = idx.to(device)\n",
    "            logits = model(idx)[:, -1, :]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            _, idx_next = torch.topk(probs, k=1, dim=-1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        txt = \" \".join(\n",
    "                    [tokenizer.id_to_token(idx[0, _]) for _ in range(maxlen)]\n",
    "                )\n",
    "    return txt\n",
    "\n",
    "start_token = 'voldemort'\n",
    "#generate(rnn, start_token, 'cuda', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvsuJHMBlm9y",
    "outputId": "21e9da66-cfa7-4373-877d-24479a0a40db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl9MQCp9TLCh"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtR1RoSBkARg",
    "outputId": "20da4eac-49e3-4568-ac7f-74dd0fec47dc",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for interval is 0.8639 sec\n",
      "Time for epoch 0 is 0.8635 sec Train loss: 6.7187\n",
      "Output: voldemort quick t know of countercurses ! he said harry everyone fingers opera , said harry spite . harry and buy families taken gotten ; window whichever jokes , facing stored in a noble a patient said the seating , but warned were sounded to the seating ; a roof harry enraged , tut suddenly , said parents yes we . i tantrum\n",
      "\n",
      "Time for interval is 34.4403 sec\n",
      "Time for epoch 50 is 0.6617 sec Train loss: 0.3098\n",
      "Output: voldemort hermione . pointing , first face came , invisible , as the white over the was for , harry fell up ! out exploded , as he was it from his yeah was a battle hair . this goes dumbledore went as professor mcgonagall anything so s thin feeling professor so fast asleep . a great hall of stone ones , or\n",
      "\n",
      "Time for interval is 34.0541 sec\n",
      "Time for epoch 100 is 0.6586 sec Train loss: 0.1942\n",
      "Output: voldemort hermione . pointing , hermione answered as before us , or be gleaming me , and to hagrid next . they climbed out , in the world . she thinks everyone knows quirrell stars feeling inside . demanded cared a few things two dragon , it , mad looking it out what on me , percy mr . lily an knock as\n",
      "\n",
      "Time for interval is 34.1256 sec\n",
      "Time for epoch 150 is 0.6646 sec Train loss: 0.0954\n",
      "Output: voldemort hermione . pointing , and tell a christmas a wide ) off , that hagrid . for , they , and yelled together up stories , said , it , his yeah to everybody i don expect . harry , to know the an are these each face looking , i didn and me him that a wise well , feeling new\n",
      "\n",
      "Time for interval is 34.1490 sec\n",
      "Time for epoch 200 is 0.6600 sec Train loss: 0.0781\n",
      "Output: voldemort hermione . underneath you won t tell before his eyes ) . about the oh , how quirrell , and wizardry . out his nerves , said , ronan , so what has have . professor must expect , ronan about as the street . las bellowed . how it thought i was an everything that a name , the poison knew\n",
      "\n",
      "Time for interval is 34.0345 sec\n",
      "Time for epoch 250 is 0.6524 sec Train loss: 0.0720\n",
      "Output: voldemort hermione . pointing , away . while for , said harry a fast britain , and to the open . now . the loud classes , said , your best stop yeah a lot o inside . and , flamel , said harry to struggle or the out how it goes potter from ? . how the greatest , the feeling yours\n",
      "\n",
      "Time for interval is 33.8792 sec\n",
      "Time for epoch 300 is 0.7589 sec Train loss: 0.0679\n",
      "Output: voldemort hermione . pointing , away . a . could logic . the girl an i , for quirrell , in the ! out . loads , said , it , longbottom , has . i don knew all . flamel excitedly . finnigan . this for a wants to harry felt , his who s how hags hands , the feeling they\n",
      "\n",
      "Time for interval is 33.9909 sec\n",
      "Time for epoch 350 is 0.6664 sec Train loss: 0.0863\n",
      "Output: voldemort hermione . ron , which of its hands my wand that . its . let was kindling , well , now . out onto ronan , said , hermione granger under well , on me open away a alley , to his tracks dragon . how ready . an it up , so who s how potatoes , said together , or\n",
      "\n",
      "Time for interval is 34.0431 sec\n",
      "Time for epoch 400 is 0.6590 sec Train loss: 0.0713\n",
      "Output: voldemort hermione . ron , which of its snout . anyway , the other have , and to the open . a my clock as much players gasped . it , so what s about where are . this , harry waved , i ve to take and broke looking she was , and me . she stopped . it , feeling the\n",
      "\n",
      "Time for interval is 34.0336 sec\n",
      "Time for epoch 450 is 0.6534 sec Train loss: 0.0611\n",
      "Output: voldemort hermione . as pure the son about , harry . i bin , the , . honestly , they had t my apart suggested bright players screamed . i his wand professor mcgonagall . where snape must like professor dumbledore and i ; looking , arms ; out how it out about the broom . he the floor ? the invisibility see\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    report = train(model, device, train_loader, optimizer, epoch)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'\\nTime for interval is {time.time()-start:.4f} sec')\n",
    "        start = time.time()\n",
    "        print(report)\n",
    "        generated_text = generate(model, start_token, device, maxlen)\n",
    "        print(f'Output: {generated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "NFv4za4O7ebh",
    "outputId": "682a2a63-685e-4b10-9441-24d5b62f1649"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'voldemort will be able to get the stone ? i m not going to be able to get the stone , but i don t know , he said . i m not going to be in ? harry asked . harry , who was very pleased he d seen in the middle , a few seconds later , the stubs of horns and bulging , orange and the next second , harry was awake and a pair of galoshes were outside the corridor , the very last thing harry had been looking forward to harry"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_token = 'voldemort'\n",
    "generated_text = generate(rnn, start_token, device, maxlen)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyC-fm4x7ebh"
   },
   "source": [
    "## Ejercicio\n",
    "- Incrementar el tamaño del dataset utilizando todos los libros de _Harry Potter_.\n",
    "- Entrenar con diferentes métodos de de Tokenización."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
