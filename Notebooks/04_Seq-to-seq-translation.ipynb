{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843670d1-04f9-4a46-9f1c-fa0e1b4f92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257dac3e-4b4f-4eac-964d-4949e9c7c070",
   "metadata": {},
   "source": [
    "## Descargar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c0293e-4292-4aef-82f8-d81a0a8b35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = keras.utils.get_file(\n",
    "    fname=\"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7fc76-9a5e-44c5-9845-2edc4a9e9d02",
   "metadata": {},
   "source": [
    "## Preparar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b71cea7-5bc5-4b94-8bc3-7cee706c0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "    \n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    spa = \"[start] \" + spa + \" [end]\"\n",
    "    text_pairs.append((eng, spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8956c567-5805-4435-94a0-453b90b498f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This smells like cheese.', '[start] Esto huele a queso. [end]')\n",
      "('How old is this airplane?', '[start] ¿Qué antigüedad tiene el avión? [end]')\n",
      "(\"As long as you're here, you'd better take a bath.\", '[start] Ya que estás aquí, sería mejor que te metieras a la tina. [end]')\n",
      "(\"I'll have to tell her the truth tomorrow.\", '[start] Tendré que decirle la verdad mañana. [end]')\n",
      "(\"Do you think it'll rain today?\", '[start] ¿Crees que hoy va a llover? [end]')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3cd4ad2-f792-4728-a61f-f10407f27f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964 total pairs\n",
      "83276 training pairs\n",
      "17844 validation pairs\n",
      "17844 test pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544172c-60cc-4039-b5ef-968fd3776012",
   "metadata": {},
   "source": [
    "## Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb61fb7f-164f-44d8-b974-1118f55f3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 6\n",
    "batch_size = 64\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\", \n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "spa_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_spa_texts = [pair[1] for pair in train_pairs]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "spa_vectorization.adapt(train_spa_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d84341-8e27-46be-9fb3-a885633ba23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int64, numpy=\n",
       "array([[ 19, 234,   8,   0,   0,   0],\n",
       "       [ 19, 169,   8,   0,   0,   0]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_vectorization([['my name is'], ['my dog is']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9089253b-7dcd-4371-8b55-91f3c9bdb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab556a43-d722-45a7-8a44-9f0df5c1d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(eng, spa):\n",
    "    eng = eng_vectorization(eng)\n",
    "    spa = spa_vectorization(spa)\n",
    "    return eng, spa\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(AUTOTUNE).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e60e15f-35a7-496e-93e0-54c81128351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  21   54   42 4300  902    0], shape=(6,), dtype=int64) tf.Tensor([   2    6   26   25 1562   10], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(inputs[0], targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1220a01b-db62-412b-b160-d1e12547c6f3",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78780696-1f80-46cf-9ab5-f80d32072f11",
   "metadata": {},
   "source": [
    "<img src=\"../img/seq-to-seq.png\" width=\"700\"/>\n",
    "\n",
    "__Imagen tomada de Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36cac235-72b2-4550-9b86-dc55ef68e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "model_dim = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86988d-5d37-4f81-92f4-9dd5f2b8b661",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ba4172-b3ac-429e-8904-defdccac7394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       "array([[ 1.4115733e-03, -5.6641502e-03,  7.7767288e-03, ...,\n",
       "        -2.1856262e-03,  6.8079270e-03, -3.3179838e-03],\n",
       "       [-1.5338659e-04,  8.9565560e-04,  1.4615036e-02, ...,\n",
       "        -2.6571031e-03,  1.5832810e-02, -1.4347886e-02],\n",
       "       [ 8.2857776e-03,  7.9951007e-03, -5.5211955e-03, ...,\n",
       "         2.2308517e-03,  4.4789212e-03, -2.3887341e-03],\n",
       "       ...,\n",
       "       [ 3.7649382e-04, -3.6410286e-04,  1.4612420e-02, ...,\n",
       "        -1.1922809e-03,  1.3411153e-02, -1.2046176e-02],\n",
       "       [ 6.9277938e-03,  3.2389206e-03, -9.4464412e-03, ...,\n",
       "         1.0154737e-02, -1.6668520e-05,  3.8765070e-03],\n",
       "       [ 8.1081139e-03, -6.4555574e-03, -1.3942542e-03, ...,\n",
       "         9.1293324e-03, -8.1743661e-04, -1.4563942e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, voc_size, emb_dim, model_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(voc_size,\n",
    "                                                   emb_dim)\n",
    "        self.gru = tf.keras.layers.GRU(model_dim,\n",
    "                                       return_sequences=False,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, state=None):\n",
    "        x = self.embedding(x)\n",
    "        x, state = self.gru(x, initial_state=state)\n",
    "        return x, state\n",
    "    \n",
    "    \n",
    "encoder = Encoder(eng_vectorization.vocabulary_size(),\n",
    "                  emb_dim, model_dim)\n",
    "output, enc_state = encoder(inputs)\n",
    "enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916c397c-61aa-4df8-a426-c21fc10d20ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  3074048   \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,012,352\n",
      "Trainable params: 7,012,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3933a535-d9cc-4d85-8ab9-650ec0d9bb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b656b-d6c8-4bd5-9139-8aba17babe4e",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a606a2c6-8069-4ac0-984d-f1177837fdd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 1, 15000), dtype=float32, numpy=\n",
       " array([[[ 7.8998192e-04, -3.4712984e-03,  2.2515412e-03, ...,\n",
       "           7.3303047e-05, -2.7270168e-03, -8.6499471e-04]],\n",
       " \n",
       "        [[ 1.3638984e-03, -5.3860024e-03,  1.9304282e-03, ...,\n",
       "           4.8100349e-04, -4.7541675e-03,  1.2959538e-03]],\n",
       " \n",
       "        [[-2.4067070e-03,  2.5511777e-04,  3.1165795e-03, ...,\n",
       "           1.5344174e-03, -2.0976199e-03,  1.0727898e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 8.9684944e-04, -5.3197448e-03,  2.0059876e-03, ...,\n",
       "           7.4011838e-04, -4.6217931e-03,  1.0152514e-03]],\n",
       " \n",
       "        [[ 1.7780627e-03, -2.9438213e-03,  2.9751225e-03, ...,\n",
       "           2.0170195e-03,  5.7476037e-04,  1.6370494e-04]],\n",
       " \n",
       "        [[ 6.5653381e-04, -2.8479625e-03,  3.2723062e-03, ...,\n",
       "           1.2746839e-03, -1.5705393e-03,  8.6521095e-04]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       " array([[-5.4189241e-03,  1.1348363e-03,  1.8043757e-03, ...,\n",
       "         -2.6944506e-03, -4.5230445e-03, -2.3274589e-03],\n",
       "        [-6.0496423e-03,  3.5602327e-03,  5.2843583e-03, ...,\n",
       "         -2.7832207e-03,  7.4980424e-05, -8.2727717e-03],\n",
       "        [-3.0930426e-03,  8.0796164e-03, -4.7683376e-03, ...,\n",
       "         -1.0954930e-03, -4.6946974e-03, -1.7209544e-03],\n",
       "        ...,\n",
       "        [-6.0640299e-03,  2.9510539e-03,  5.4876781e-03, ...,\n",
       "         -1.8202143e-03, -9.3511579e-04, -7.0668301e-03],\n",
       "        [-3.8552880e-03,  6.7047430e-03, -8.2292752e-03, ...,\n",
       "          3.6484331e-03, -6.2628514e-03,  9.0513419e-04],\n",
       "        [-2.5279208e-03,  8.3350524e-04, -2.8431397e-03, ...,\n",
       "          1.5541348e-03, -8.5205212e-03, -6.9571920e-03]], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, voc_size, emb_dim, model_dim):\n",
    "        super().__init__(self)\n",
    "        self.embedding = layers.Embedding(voc_size, emb_dim)\n",
    "        self.gru = layers.GRU(model_dim,\n",
    "                              return_sequences=True,\n",
    "                              return_state=True)\n",
    "        self.logits = layers.Dense(voc_size)\n",
    "\n",
    "    def call(self, x, state, training=False):\n",
    "        x = self.embedding(x, training=training)\n",
    "        x, state = self.gru(x, initial_state=state, training=training)\n",
    "        x = self.logits(x, training=training)\n",
    "\n",
    "        return x, state\n",
    "\n",
    "\n",
    "decoder = Decoder(voc_size=spa_vectorization.vocabulary_size(),\n",
    "                  emb_dim=emb_dim,\n",
    "                  model_dim=model_dim)\n",
    "\n",
    "decoder(targets[:, :1], enc_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6fd6976-05a1-446b-be33-db7b8747035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  3840000   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  15375000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,153,304\n",
      "Trainable params: 23,153,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d773b6cc-1f5c-4251-bf66-d810aba70357",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87162be7-ffe4-41d8-9385-db9ae41f0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56fafdc4-8a0c-4a16-a127-5ee4367ff38e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       "array([[ 1.4115733e-03, -5.6641502e-03,  7.7767288e-03, ...,\n",
       "        -2.1856262e-03,  6.8079270e-03, -3.3179838e-03],\n",
       "       [-1.5338659e-04,  8.9565560e-04,  1.4615036e-02, ...,\n",
       "        -2.6571031e-03,  1.5832810e-02, -1.4347886e-02],\n",
       "       [ 8.2857776e-03,  7.9951007e-03, -5.5211955e-03, ...,\n",
       "         2.2308517e-03,  4.4789212e-03, -2.3887341e-03],\n",
       "       ...,\n",
       "       [ 3.7649382e-04, -3.6410286e-04,  1.4612420e-02, ...,\n",
       "        -1.1922809e-03,  1.3411153e-02, -1.2046176e-02],\n",
       "       [ 6.9277938e-03,  3.2389206e-03, -9.4464412e-03, ...,\n",
       "         1.0154737e-02, -1.6668520e-05,  3.8765070e-03],\n",
       "       [ 8.1081139e-03, -6.4555574e-03, -1.3942542e-03, ...,\n",
       "         9.1293324e-03, -8.1743661e-04, -1.4563942e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, state = encoder(inputs)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad6a29b-b44b-4b83-8f28-50ad712cba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad8ca11-06d8-4cd1-bfc2-bb5e3c56236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  75   24    5 1174   55  216]\n",
      " [ 321  203 1547    0    0    0]\n",
      " [   6   43  715   26  368    9]], shape=(3, 6), dtype=int64) tf.Tensor(\n",
      "[[   2   16   27   14 1124  234]\n",
      " [   2   13  103   17 5188    3]\n",
      " [   2    8  583    6   30  213]], shape=(3, 6), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(inputs[:3], targets[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adc2cf2b-f7a7-413b-a56d-8172bca9d91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
       "array([  24,  203,   43,   12,  187,    5,  266,  127,  176,   27,  564,\n",
       "         59,  642,  239, 3910,   65,   38,    5,   57,   10,  701,    8,\n",
       "          3,  597, 1537,  266,   49, 3900,   37,    9, 3698,    8,  388,\n",
       "        131,   43,   99,  985,   28,   99,  151,   16,  145, 9522,   35,\n",
       "        116,  244,  871,  112,   99,   22,  248,  537,   17, 1928,  318,\n",
       "       1219, 1409,   14,   44,  618,    5,  396,  170,  148])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3ed1-c4d0-4aa1-9ee0-e77502629d9b",
   "metadata": {},
   "source": [
    "- Utilizar _Teacher forcing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea2bd42b-e98f-4abb-9d04-324d55b6ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp_batch, tar_batch):\n",
    "    loss = tf.constant(0.0)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, state = encoder(inp_batch, training=True)\n",
    "\n",
    "        for step in range(0, tar_batch.shape[1] - 1):\n",
    "            dec_inp = tf.expand_dims(tar_batch[:, step], 1)\n",
    "            pred, state = decoder(dec_inp, state, \n",
    "                                  training=True)\n",
    "            loss += loss_function(tar_batch[:, step + 1], pred)\n",
    "        total_loss = loss / tar_batch.shape[1]\n",
    "    weights = encoder.trainable_weights + decoder.trainable_weights\n",
    "    gradients = tape.gradient(total_loss, weights)   \n",
    "    opt.apply_gradients(zip(gradients, weights))\n",
    "    train_loss_avg(total_loss)\n",
    "    \n",
    "train_step(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd8c900-a636-40c5-bf51-0bae31e81894",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.368617057800293\n",
      "Loss: 1.766330361366272\n",
      "Loss: 1.0137767791748047\n",
      "Loss: 0.6187133193016052\n",
      "Loss: 0.4228934645652771\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in train_ds:\n",
    "        train_step(inputs, targets)\n",
    "        \n",
    "    print(f'Loss: {train_loss_avg.result().numpy()}')\n",
    "    train_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12b414-3283-441e-b315-bddff1244d16",
   "metadata": {},
   "source": [
    "## Probar traducción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892f30b-1802-4d71-840f-75b676372032",
   "metadata": {},
   "source": [
    "- Diccionario para recuperar palabras de índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a84e84c-d6a2-4dcf-9272-acf313a3fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_vocab = spa_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1062d8-3979-4064-ad91-33b69fed33b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me encanta mi perro'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = eng_vectorization(['i love my dog'])\n",
    "_, state = encoder(inp)\n",
    "dec_inp = spa_vectorization(['[start]'])[:, :1]\n",
    "output = []\n",
    "pred_index = ''\n",
    "\n",
    "while pred_index != '[end]':\n",
    "    pred, state = decoder(dec_inp, state, training=False)\n",
    "    dec_inp = tf.argmax(pred, axis=-1)\n",
    "    pred_index = spa_index_lookup[dec_inp[0][0].numpy()]\n",
    "    output.append(pred_index)\n",
    "    \n",
    "' '.join(output[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea56a3-e1ca-4101-a463-9b1146507bec",
   "metadata": {},
   "source": [
    "- El modelo original Seq-to-seq es difícil de entrenar en secuencias largas debido a los problemas de las redes recurrentes; por eso, estos modelos se complementan con mecanismos de atención o se remplazan completamente por arquitecturas como Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa7858-1f2a-492f-8a55-a454c2f3ae2a",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Remplazar GRU por LSTM.\n",
    "- Agregar __test_step__ para monitoriear el entrenamiento sin _Teacher forcing_.\n",
    "- Mejorar el modelo con las técnicas propuestas en _Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27._\n",
    "- Modificar longitud de secuencia, arquitecture e hiperparámetros, agreagar mecanismo de atención de _Bahdanau_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
