{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc49d9b-5f41-4169-bbda-5d77f285459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c4517-86bd-4ed3-836a-f7356c895317",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3404f6ab-2dd4-4c7e-989a-ea33ee8c14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342afe6a-fe93-4832-b573-96f8e209cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('imdb_reviews', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155f67f-344e-4841-adab-3a2e58608756",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds, raw_test_ds = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dae875-74f1-46d0-a402-03cf4bdd4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\" 0\n"
     ]
    }
   ],
   "source": [
    "for text, label in raw_train_ds.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e327c-6df0-4bde-8dc3-d67f22a8fb29",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4102ef0a-84b1-4e12-97c1-b06627d29349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BUFFER_SIZE = tf.data.experimental.cardinality(raw_train_ds)\n",
    "BUFFER_SIZE.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2418bc02-1d92-40e9-9c02-59d46bc8c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8652f61b-9976-4771-b024-f3a62c59d23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'My favorite dog'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.regex_replace('My favorite dog?', f\"([{string.punctuation}])\", r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6861a39-c479-4bd5-8344-bb8d25c7db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "voc_size = 5000\n",
    "max_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03806b63-ba07-4258-8d33-ec700e8ec4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw_text, label):\n",
    "    lowercase = tf.strings.lower(raw_text)\n",
    "    lowercase = tf.strings.substr(lowercase, 0, max_length)\n",
    "    clean = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    clean = tf.strings.regex_replace(clean, \n",
    "                                     f\"([{string.punctuation}])\", r\"\")\n",
    "    return clean, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5064dcdb-293a-4cf0-a7a9-235bebfff98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'this was an absolutely terrible movie dont be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movies ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revol', shape=(), dtype=string)\n",
      "tf.Tensor(b'this was an absolutely terrible movie dont be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movies ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revol', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_ds = raw_train_ds.map(clean_text)\n",
    "\n",
    "for text, label in train_ds.take(1):\n",
    "    print(text)\n",
    "    print(tf.strings.substr(\n",
    "    text, 0, max_length)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "288fb5a9-8fac-40a7-a696-d58adfa6d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(clean_text).shuffle(BUFFER_SIZE).batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)\n",
    "\n",
    "test_ds = raw_test_ds.map(clean_text).batch(\n",
    "        batch_size, num_parallel_calls=AUTOTUNE).prefetch(\n",
    "        AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa013dfc-752c-4939-8064-757f5c9b447b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'for those who are too young to know this or for those who have forgotten the disney company went almost down the tubes by the end of the 1980s people were not seeing their movies anymore and the company was not producing the usual wholesome materialat least no what people expected a major problem profanity  yes the idiots running the disney movies during that decade would produ'\n",
      " b'the first time i saw this film i loved it it was different  i am a christian bible believing i dont go along with the crowd of right wing believers i dropped out of that atmosphere  to me in their attempts to take over our government they are doing what judas tried to do i call it the judas syndrome  judas didnt get it even though jesus said his kingdom w'\n",
      " b'takashi miikes incursion into kiddie territory won me over almost immediately because he demonstrates nerve and bravery in dealing with fantasy elements this is a fairy tale that dares to be dark even as a kid i thought that there was something sinister about most fairy tales horrible things happen to people in most childrens books miike understands that these classic tales are a bit scarie'\n",
      " b'what happened doubt had so much potential to be a brilliant film  but instead it faltered with a dragging simplistic plot line which made me want to stop watching the only thing the film had going for it was the brilliance of meryl streep who no doubt deserved the oscarnomination though it was not one of her best performances she still gave a solid and truthful character to us which bloss'\n",
      " b'what a lovely heart warming television movie the story tells of a little five year old girl who has lost her daddy and finds it impossible to cope her mother is also very distressed only a miracle can alleviate their unhappinesswhich all viewers hope will materialise samantha mathis is brilliant as the little girls mum as she was as the nanny in jack and sarahworth watching if you like '\n",
      " b'though this movie has a first rate roster of fine actors special effects that are excellent and a story line that is full of surprises it wasnt picked up for studio distribution and went directly to dvd perhaps it contains too much antipolice force information or perhaps it is juts one too many action flicks released during a glut but whatever the reason the big screens missed the opport'\n",
      " b'the second half of steven soderberghs revolutionary bio on che guevara deals with his last campaign to export revolution to bolivia in order to maintain his saintly visage of che soderbergh conveniently leap frogs the mass executions he presided over after the revolution in cuba and the folly of his congo adventure this is the history of a failure he writes in the preface of his congo journal'\n",
      " b'this is a pretty strange movie it does comes across as an exploitation film with overthetop violence and unrealistic situations but unusual for being constructed around rural characters at war with each other as opposed to an invading other  the movie is an excessive stereotype of vietnam veterans in a long line of films that portrayed the vets of that war as dangerous psycopath'\n",
      " b'this started bad got worse and by the time the girl attacked the old lady at the end i literally wanted to take the dvd to the person we borrowed it off and choke the ct to death with it avoid this film a little bit of good cinematography and some naked shots would be almost acceptable if i was 14 and had not seen jenna jameson naked a million times if anyone feels the need to watch this f'\n",
      " b'well i just gave away 95 minutes and 47 seconds that ill never get back on this piece of trash i heard someone online describe this movies villains as subhuman cannibals and i thought it was promising because i thought it would be like the descent wrong the descent was a psychological thriller with dynamic characters and strong storyline these villains are totally unrealistic and no part '\n",
      " b'really i cant believe that i spent 5 on this movie i am a huge zombie fanatic and thought the movie couldnt be that bad it had zombies in it right was i wrong to be honest the movie had its momentsi thought it was cool when the guy got his head ripped off but that was about it overall i think that it would be more enjoyable to slide down a razorblade slide on my bare nutsack into a va'\n",
      " b'i watched this movie to the end and that was really not easy it is so boring bad played and in nearly every detail stolen from blair witch project that you cant believe the makers take this serious even harder to believe is how this product made it onto vhs and dvd  so if want to see a horrormovie just watch scream but if you want to laugh out loud and have a good time'\n",
      " b'all for love  as it titled when it was broadcast at the weekend  is a romantic period drama featuring captain saint ives a french officer in napoleons army who is captured by the british and imprisoned in scotland where he meets and falls in love with a young maiden who visits the prison  theres also a storyline involving a murder   i will be honest and confess that i wasnt too ta'\n",
      " b'what a fun filled sexy movie they certainly dont make them like this anymore 4 sexy au pairs arrive in london and have all sorts of sexual misadventures the tone is oddly innocent as the considerable nudity evolves out of stock farcical situations rather than any overt sexual desire on the part of the characters it is only when the actresses accidentally lose their clothes that the male ch'\n",
      " b'this film is the worst film i have ever seen the story line is weak  i couldnt even follow it the acting is highschoolish the sound track is irritating the attempts at humor are not the editing is horrible the credits are even slow  i would be embarrassed to have my name associated with this waste of film dont waste your time even thinking about this attempt at acting'\n",
      " b'during the first 3 seasons fairly odd parents was as tasty as hard candy bright and sweet and addictive now its as tasty as peptobismol and unfortunately peptobismol is what youll need after viewing the more recent episodes where all the sweetness has been replaced by insults and violence resulting in no laughs cosmo once one of the more endearing nick characters has devolved into an ab'], shape=(16,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a69291-e1ee-4d06-b8f1-9510fa3c598f",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce2541-073e-4477-a9d5-54e8f535ba79",
   "metadata": {},
   "source": [
    "<img src=\"../img/bert.png\" width=\"700\"/>\n",
    "\n",
    "__Imagen tomada de Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76ca6b3-9bd2-42e0-82bb-d7c6d06cc63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, _ = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d417aa6-b8c7-4a7b-9ba2-15e228080b67",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=string, numpy=\n",
       "array([b'one of my favorite twilight zone episodes and the next day we were in the supermarket at hollywood blvd and la brea my father and i and guess who was coming toward us in the aisle barney phillips but no hat on  at least i dont think he had a hat on  we asked him about his third eye and he said something like he left it at home and everybody he met that day had asked him abou',\n",
       "       b'this is the sort of thing that only now thrills the film eggheads after all feiersteins flex crush will have you know that real men dont watch anything by truffaut   it might have been interesting if truffaut had anything to say here the cameraasvoyeur motif was nothing new have we all forgotten de sicas bicycle thief or anything by hitchcock  so all we get is t',\n",
       "       b'probably the only thing that got the movie up to a four for me is the fact that i love peter falk one of the worlds great portrayers of bumbling incompetence    and yet he is one of the only anchors that prevents this from being a chaotic disaster as pops romano he provides a respectable mix of gangster charm and straight man to chris kattans manic foolishness respectable performances are',\n",
       "       b'when you look at this now and hear all the language in here its amazing this was rated pg but thats the 1970s rating system for you peter falk spews out the lords name in vain six times in the first ten minutes alone in this movie yet few people consider that offensive and certainly not the scumbags who make movies nor the people who rate them  the cast is a clue to how pro',\n",
       "       b'barbra streisands debut television special is still a pinnacle moment in entertainment history  in any media cleverly divided into three separate acts to minimize the interruption of commercial breaks streisand made the boldyetmasterful decision to drop the typical variety show format of the time which is why there is no guest stars nor forced banter and carry the entire show on her shou',\n",
       "       b'this is just a case of a previously worthless island changed into something worthwhile jesus christ people lets throw a big fit over 2000 islanders big dealthis is just a case of a previously worthless island changed into something worthwhile jesus christ people lets throw a big fit over 2000 islanders big dealthis is just a case of a previously worthless island changed into something worthwhi',\n",
       "       b'loved it but still have nightmares over the hotel managerthe movie was presented well with the choice of actors carrying their roles to reality of the writing many scenes gripped the imagination and created a nail biter the progression of situations were cleverly writtenmaking me believe the story was headed one way only to find a new twist on what i thought might be the obvious too bad the',\n",
       "       b'after the success of the second instalment richard curtis and ben elton decided that blackadder should have a third appearance this time instead of tudor times or elizabethan times edmund blackadder bafta nominated rowan atkinson is living in the time of the french revolution accompanied by the now stupid but lovable baldrick tony robinson blackadder is the faithful butler to george the',\n",
       "       b'impactful film of four city slickers in crisis in appalachia has become synonymous with rural depravity each of four businessmen face their darkest fears when they tackle a challenging whitewater trip on a river about to be replaced by a dam when locals along the way decide to have their way with the interlopers it leads to several deaths and loads of trauma for the survivors each of the tra',\n",
       "       b'laurence olivier merle oberon ralph richardson and binnie barnes star in the divorce of lady x a 1938 comedy based on a play olivier plays a young barrister everard logan who allows oberon to spend the night in his hotel room when the london fog is too dense for guests at a costume ball to go home the next day a friend of his lord mere richardson announces that his wife barnes spe',\n",
       "       b'the storyline of the thief of bagdad is complex owing to its being told in flashbacks and having three separate and equally important strands woven together the screenplay by lajo biros and the dialogue by miles malleson keep the story moving skillfully at all pointsthe young king ahmad of bagdad is angry at his vizier jaffar for executing a man for having different ideas he discovers while',\n",
       "       b'i was lucky enough to attend a screening in stockholm for this elegantly expressed enjoyable and thoughtprovoking film with romance as the heaviest weapon in its arsenal paris je taime boldly plunges into love in paris navigating the different forms in eighteen separate quartiers but without pouting parisiennes and saccharine formulas its goldmine undoubtedly stems from frustration on th',\n",
       "       b'i read this thornton wilder play last year in eighth grade i was also forced to sit through this weak translation of it on screen let me tell you its not a terrific play it is easily surpassed but man it deserves a much better shot the acting was really lacking the sceneryhonest to godlooked like it was designed out of cardboard by a group of threeyearolds as if it couldnt get worse',\n",
       "       b'it was almost worth sitting through this entire godawful film just to know that i can never experience anything as bad as this again acting  0 script  0 fight scenes  0 male lead  0 cheddar bob from eight mile as a suave war hero who gets the girl nadia bjorlin  10 she is gorgeous and not a terrible actress this is the criteria i used to average it out to a two i lost count but ',\n",
       "       b'before i give spike lees mess of a film summer of sam a welldeserved thrashing i would like to make one thing clear i do not revile this film simply for its abundance of sleazy and unpleasant images what makes this film so unwatchable is the fact that lee seems to believe that summer of sam should be taken seriously as a socially enlightening drama the crime caper films of quentin tarantino',\n",
       "       b'i have to say that the events of 911 didnt hit me until i saw this documentary it took me a year to come to grips with the devastation i was the one who was changing the station on the radio and channel on tv if there was any talk about the towers i was sick of hearing about it when this was aired on tv a year and a day later i was bawling my eyes out it was the first time i had cried sinc'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "530db00c-060e-46ea-a731-b982e38aed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_path = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "bert_preprocess_path = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9d0971-e6de-4025-a8f5-354513691ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(bert_preprocess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4cb2b6c-7504-425f-8644-f29a766dcf62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_mask': <tf.Tensor: shape=(16, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(16, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>,\n",
       " 'input_word_ids': <tf.Tensor: shape=(16, 128), dtype=int32, numpy=\n",
       " array([[ 101, 2028, 1997, ...,    0,    0,    0],\n",
       "        [ 101, 2023, 2003, ...,    0,    0,    0],\n",
       "        [ 101, 2763, 1996, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2009, 2001, ...,    0,    0,    0],\n",
       "        [ 101, 2077, 1045, ...,    0,    0,    0],\n",
       "        [ 101, 1045, 2031, ...,    0,    0,    0]], dtype=int32)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_output = bert_preprocess_model(train_text)\n",
    "preprocess_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d363b6-d642-451b-8bee-3e0a9458080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(bert_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "012b50b8-c9be-4924-ab50-dcf1f2c8abc4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 512), dtype=float32, numpy=\n",
       "array([[ 0.00314083,  0.9803104 ,  0.0247332 , ..., -0.09464012,\n",
       "        -0.27182636, -0.8748782 ],\n",
       "       [-0.33249202,  0.97886175, -0.13606362, ...,  0.4085269 ,\n",
       "        -0.04963234,  0.0699869 ],\n",
       "       [ 0.53238064,  0.84037936, -0.03310442, ...,  0.23471183,\n",
       "        -0.02497339, -0.14739855],\n",
       "       ...,\n",
       "       [ 0.03954168,  0.9674722 , -0.26850796, ...,  0.17178895,\n",
       "        -0.25081205, -0.41408285],\n",
       "       [-0.70664436,  0.9434369 , -0.3560397 , ...,  0.07197679,\n",
       "        -0.23364528, -0.6748686 ],\n",
       "       [ 0.37896913,  0.97541744,  0.10970975, ..., -0.17064568,\n",
       "        -0.4797275 , -0.66744995]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model(preprocess_output)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59d56968-9a5f-4dec-adaf-a4e7d8f66f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), \n",
    "                                   dtype=tf.string, name='text')\n",
    "preprocess_text = bert_preprocess_model(text_input)\n",
    "bert_output = bert_model(preprocess_text)['pooled_output']\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(bert_output)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "small_bert = tf.keras.Model(text_input, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea47915-00bb-42f5-81e4-d33d3e37b4be",
   "metadata": {},
   "source": [
    "- Probar bert con batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa876b8a-c6fa-4c9d-8819-476b70288bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
       "array([[1.2523457],\n",
       "       [1.8890367],\n",
       "       [1.610847 ],\n",
       "       [2.0197604],\n",
       "       [1.5687854],\n",
       "       [2.0456805],\n",
       "       [1.8366705],\n",
       "       [1.3767264],\n",
       "       [1.7974275],\n",
       "       [0.9964155],\n",
       "       [1.5116007],\n",
       "       [1.6900955],\n",
       "       [1.9164311],\n",
       "       [1.8237029],\n",
       "       [1.9688467],\n",
       "       [1.3759558]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_bert(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfca56a-eb6d-418c-9b11-4a5300ab9bd1",
   "metadata": {},
   "source": [
    "- Información del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a315c30f-f107-43fa-b5d6-1a4334ff0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'encoder_outputs':  28763649    ['keras_layer[0][0]',            \n",
      "                                 [(None, 128, 512),               'keras_layer[0][1]',            \n",
      "                                 (None, 128, 512),                'keras_layer[0][2]']            \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                512)}                                                             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          65664       ['keras_layer_1[0][5]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,829,442\n",
      "Trainable params: 65,793\n",
      "Non-trainable params: 28,763,649\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "small_bert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78948806-9b9b-4a4b-960b-e3668b750240",
   "metadata": {},
   "source": [
    "## Entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29a2b23f-a780-4b94-b280-5feeecc07ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f299f93-f2ac-4964-a2fb-bdfd7668217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6578dcd0-2eca-4a94-8d6d-2efbba652d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss_avg = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f131dd23-8c8f-450c-9a86-b5c6b71a2868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, <tf.Tensor: shape=(), dtype=int64, numpy=1563>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds), tf.data.experimental.cardinality(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73f48684-b2e5-4698-90e1-1ecb05d73ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = small_bert(text, training=True)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, small_bert.trainable_weights)\n",
    "    opt.apply_gradients(zip(gradients, small_bert.trainable_weights))\n",
    "    train_loss_avg(loss_value)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(text, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = small_bert(text, training=False)\n",
    "        loss_value = loss(tf.cast(target, tf.float32), logits)\n",
    "\n",
    "    val_loss_avg(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a761811b-6555-43e6-ae7a-031c50781aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "426bc9e1-41ff-4174-be93-2e045ba30036",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train loss: 0.582028329372406\n",
      "Val loss: 0.551526665687561\n",
      "Epoch: 1 Train loss: 0.5433706641197205\n",
      "Val loss: 0.5400358438491821\n",
      "Epoch: 2 Train loss: 0.5347903370857239\n",
      "Val loss: 0.5484887957572937\n",
      "Epoch: 3 Train loss: 0.5298752188682556\n",
      "Val loss: 0.5331859588623047\n",
      "Epoch: 4 Train loss: 0.5242843627929688\n",
      "Val loss: 0.5345173478126526\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for text, target in train_ds:\n",
    "        train_step(text, target)\n",
    "        \n",
    "    print(f'Epoch: {epoch} Train loss: {train_loss_avg.result().numpy()}')\n",
    "    train_loss_avg.reset_states()\n",
    "    \n",
    "    for text, target in test_ds:\n",
    "        test_step(text, target)\n",
    "        \n",
    "    print(f'Val loss: {val_loss_avg.result().numpy()}')\n",
    "    val_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1df65d-ba82-4850-b59b-768a3cc8ff51",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Modificar la arquitectura para obtener mejores resultados.\n",
    "- Probar diferentes versiones de BERT: https://tfhub.dev/google/collections/bert/1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
